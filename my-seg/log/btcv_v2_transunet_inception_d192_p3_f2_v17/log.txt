[2023/01/16 16:38] | ---------------------------------------------------------------------------------
[2023/01/16 16:38] |                                    INFORMATION
[2023/01/16 16:38] | ---------------------------------------------------------------------------------
[2023/01/16 16:38] | Project Name              | MESEG
[2023/01/16 16:38] | Project Administrator     | jaejung
[2023/01/16 16:38] | Experiment Name           | btcv_v2_transunet_inception_d192_p3_f2_v17
[2023/01/16 16:38] | Experiment Start Time     | 2023-01-16 16:38:29
[2023/01/16 16:38] | Experiment Model Name     | transunet_inception_d192_p3_f2
[2023/01/16 16:38] | Experiment Log Directory  | log/btcv_v2_transunet_inception_d192_p3_f2_v17
[2023/01/16 16:38] | ---------------------------------------------------------------------------------
[2023/01/16 16:38] |                                 EXPERIMENT SETUP
[2023/01/16 16:38] | ---------------------------------------------------------------------------------
[2023/01/16 16:38] | train_size                | (224, 224)
[2023/01/16 16:38] | test_size                 | (224, 224)
[2023/01/16 16:38] | center_crop_ptr           | 0.875
[2023/01/16 16:38] | interpolation             | bicubic
[2023/01/16 16:38] | mean                      | (0.485, 0.456, 0.406)
[2023/01/16 16:38] | std                       | (0.229, 0.224, 0.225)
[2023/01/16 16:38] | hflip                     | 0.5
[2023/01/16 16:38] | auto_aug                  | False
[2023/01/16 16:38] | cutmix                    | None
[2023/01/16 16:38] | mixup                     | None
[2023/01/16 16:38] | remode                    | None
[2023/01/16 16:38] | model_name                | transunet_inception_d192_p3_f2
[2023/01/16 16:38] | lr                        | 0.01
[2023/01/16 16:38] | epoch                     | 1
[2023/01/16 16:38] | criterion                 | dicece
[2023/01/16 16:38] | optimizer                 | sgd
[2023/01/16 16:38] | weight_decay              | 0.0001
[2023/01/16 16:38] | scheduler                 | None
[2023/01/16 16:38] | warmup_epoch              | 5
[2023/01/16 16:38] | batch_size                | 24
[2023/01/16 16:38] | ---------------------------------------------------------------------------------
[2023/01/16 16:38] |                                   DATA & MODEL
[2023/01/16 16:38] | ---------------------------------------------------------------------------------
[2023/01/16 16:38] | Model Parameters(M)       | 107559769
[2023/01/16 16:38] | Number of Train Examples  | 2211
[2023/01/16 16:38] | Number of Valid Examples  | 12
[2023/01/16 16:38] | Number of Class           | 9
[2023/01/16 16:38] | ---------------------------------------------------------------------------------
[2023/01/16 16:38] | TRAIN(000): [ 1/93] Batch: 9.0496 (9.0496) Data: 0.0262 (0.9503) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [ 2/93] Batch: 0.6621 (4.8558) Data: 0.0115 (0.6374) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [ 3/93] Batch: 0.6628 (3.4582) Data: 0.0169 (0.4823) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [ 4/93] Batch: 0.6570 (2.7579) Data: 0.0128 (0.3884) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [ 5/93] Batch: 0.6578 (2.3378) Data: 0.0141 (0.3260) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [ 6/93] Batch: 0.6537 (2.0572) Data: 0.0120 (0.2811) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [ 7/93] Batch: 0.6492 (1.8560) Data: 0.0151 (0.2479) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [ 8/93] Batch: 0.6592 (1.7064) Data: 0.0183 (0.2224) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [ 9/93] Batch: 0.6477 (1.5888) Data: 0.0129 (0.2014) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [10/93] Batch: 0.6568 (1.4956) Data: 0.0156 (0.1845) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [11/93] Batch: 0.6584 (1.4195) Data: 0.0095 (0.1700) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [12/93] Batch: 0.6332 (1.3540) Data: 0.0081 (0.1575) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [13/93] Batch: 0.6345 (1.2986) Data: 0.0086 (0.1469) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [14/93] Batch: 0.6375 (1.2514) Data: 0.0099 (0.1377) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [15/93] Batch: 0.6502 (1.2113) Data: 0.0151 (0.1301) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [16/93] Batch: 0.6477 (1.1761) Data: 0.0160 (0.1234) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [17/93] Batch: 0.6722 (1.1464) Data: 0.0126 (0.1172) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [18/93] Batch: 0.6623 (1.1195) Data: 0.0236 (0.1123) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [19/93] Batch: 0.6638 (1.0956) Data: 0.0157 (0.1075) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [20/93] Batch: 0.6397 (1.0728) Data: 0.0133 (0.1030) Loss: 0.0000 (0.0000)
[2023/01/16 16:38] | TRAIN(000): [21/93] Batch: 0.6387 (1.0521) Data: 0.0098 (0.0987) Loss: 0.0000 (0.0000)

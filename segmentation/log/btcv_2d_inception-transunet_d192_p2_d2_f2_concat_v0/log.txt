[2023/02/02 15:18] | ---------------------------------------------------------------------------------
[2023/02/02 15:18] |                                    INFORMATION
[2023/02/02 15:18] | ---------------------------------------------------------------------------------
[2023/02/02 15:18] | Project Name              | MESEG
[2023/02/02 15:18] | Project Administrator     | jaejung
[2023/02/02 15:18] | Experiment Name           | btcv_2d_inception-transunet_d192_p2_d2_f2_concat_v0
[2023/02/02 15:18] | Experiment Start Time     | 2023-02-02 15:17:56
[2023/02/02 15:18] | Experiment Model Name     | inception-transunet_d192_p2_d2_f2_concat
[2023/02/02 15:18] | Experiment Log Directory  | log/btcv_2d_inception-transunet_d192_p2_d2_f2_concat_v0
[2023/02/02 15:18] | ---------------------------------------------------------------------------------
[2023/02/02 15:18] |                                 EXPERIMENT SETUP
[2023/02/02 15:18] | ---------------------------------------------------------------------------------
[2023/02/02 15:18] | train_size                | (224, 224)
[2023/02/02 15:18] | test_size                 | (224, 224)
[2023/02/02 15:18] | center_crop_ptr           | 0.875
[2023/02/02 15:18] | interpolation             | bicubic
[2023/02/02 15:18] | mean                      | (0.485, 0.456, 0.406)
[2023/02/02 15:18] | std                       | (0.229, 0.224, 0.225)
[2023/02/02 15:18] | hflip                     | 0.5
[2023/02/02 15:18] | auto_aug                  | False
[2023/02/02 15:18] | cutmix                    | None
[2023/02/02 15:18] | mixup                     | None
[2023/02/02 15:18] | remode                    | None
[2023/02/02 15:18] | model_name                | inception-transunet_d192_p2_d2_f2_concat
[2023/02/02 15:18] | lr                        | 0.01
[2023/02/02 15:18] | epoch                     | 150
[2023/02/02 15:18] | criterion                 | dicece
[2023/02/02 15:18] | optimizer                 | sgd
[2023/02/02 15:18] | weight_decay              | 0.0001
[2023/02/02 15:18] | scheduler                 | cosine
[2023/02/02 15:18] | warmup_epoch              | 0
[2023/02/02 15:18] | batch_size                | 24
[2023/02/02 15:18] | ---------------------------------------------------------------------------------
[2023/02/02 15:18] |                                   DATA & MODEL
[2023/02/02 15:18] | ---------------------------------------------------------------------------------
[2023/02/02 15:18] | Model Parameters(M)       | 23,437,849
[2023/02/02 15:18] | Number of Train Examples  | 2,211
[2023/02/02 15:18] | Number of Valid Examples  | 12
[2023/02/02 15:18] | Number of Class           | 9
[2023/02/02 15:18] | ---------------------------------------------------------------------------------
[2023/02/02 15:18] | TRAIN(e000|iter0): [ 0/93] Batch: 0.0000 (0.0000) Data: 0.6777 (0.6777) Loss: 1.6853 (1.6853)
[2023/02/02 15:18] | TRAIN(e000|iter50): [50/93] Batch: 0.7266 (0.8378) Data: 0.5211 (0.5029) Loss: 0.5152 (0.6774)
[2023/02/02 15:19] | ------------------------------------------------------------
[2023/02/02 15:19] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:19] | ------------------------------------------------------------
[2023/02/02 15:19] |     TRAIN(0)     0:01:15     0:00:46     0:00:28      0.5904
[2023/02/02 15:19] | ------------------------------------------------------------
[2023/02/02 15:19] | ****************************************************************************************************
[2023/02/02 15:19] | TRAIN(e001|iter100): [ 7/93] Batch: 0.7468 (0.7793) Data: 0.5257 (0.5192) Loss: 0.4767 (0.4822)
[2023/02/02 15:20] | TRAIN(e001|iter150): [57/93] Batch: 0.7714 (0.7712) Data: 0.5466 (0.5106) Loss: 0.4423 (0.4632)
[2023/02/02 15:20] | ------------------------------------------------------------
[2023/02/02 15:20] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:20] | ------------------------------------------------------------
[2023/02/02 15:20] |     TRAIN(1)     0:01:10     0:00:46     0:00:24      0.4532
[2023/02/02 15:20] | ------------------------------------------------------------
[2023/02/02 15:20] | ****************************************************************************************************
[2023/02/02 15:20] | TRAIN(e002|iter200): [14/93] Batch: 0.7447 (0.7953) Data: 0.4997 (0.5297) Loss: 0.4171 (0.4220)
[2023/02/02 15:21] | TRAIN(e002|iter250): [64/93] Batch: 0.8101 (0.7808) Data: 0.5012 (0.5155) Loss: 0.4034 (0.4162)
[2023/02/02 15:21] | ------------------------------------------------------------
[2023/02/02 15:21] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:21] | ------------------------------------------------------------
[2023/02/02 15:21] |     TRAIN(2)     0:01:11     0:00:46     0:00:24      0.4122
[2023/02/02 15:21] | ------------------------------------------------------------
[2023/02/02 15:21] | ****************************************************************************************************
[2023/02/02 15:21] | TRAIN(e003|iter300): [21/93] Batch: 0.7405 (0.7625) Data: 0.5179 (0.5009) Loss: 0.3948 (0.4030)
[2023/02/02 15:22] | TRAIN(e003|iter350): [71/93] Batch: 0.8319 (0.7697) Data: 0.5380 (0.5078) Loss: 0.3948 (0.4009)
[2023/02/02 15:22] | ------------------------------------------------------------
[2023/02/02 15:22] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:22] | ------------------------------------------------------------
[2023/02/02 15:22] |     TRAIN(3)     0:01:11     0:00:46     0:00:24      0.4003
[2023/02/02 15:22] | ------------------------------------------------------------
[2023/02/02 15:22] | ****************************************************************************************************
[2023/02/02 15:23] | TRAIN(e004|iter400): [28/93] Batch: 0.7364 (0.7663) Data: 0.5502 (0.5051) Loss: 0.3849 (0.3932)
[2023/02/02 15:23] | TRAIN(e004|iter450): [78/93] Batch: 0.8241 (0.7754) Data: 0.5095 (0.5120) Loss: 0.3776 (0.3876)
[2023/02/02 15:24] | ------------------------------------------------------------
[2023/02/02 15:24] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:24] | ------------------------------------------------------------
[2023/02/02 15:24] |     TRAIN(4)     0:01:11     0:00:47     0:00:24      0.3865
[2023/02/02 15:24] | ------------------------------------------------------------
[2023/02/02 15:24] | ****************************************************************************************************
[2023/02/02 15:24] | TRAIN(e005|iter500): [35/93] Batch: 0.7427 (0.7799) Data: 0.4741 (0.5141) Loss: 0.3668 (0.3898)
[2023/02/02 15:25] | TRAIN(e005|iter550): [85/93] Batch: 0.7582 (0.7736) Data: 0.4583 (0.5093) Loss: 0.3553 (0.3776)
[2023/02/02 15:25] | ------------------------------------------------------------
[2023/02/02 15:25] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:25] | ------------------------------------------------------------
[2023/02/02 15:25] |     TRAIN(5)     0:01:11     0:00:46     0:00:24      0.3770
[2023/02/02 15:25] | ------------------------------------------------------------
[2023/02/02 15:25] | ****************************************************************************************************
[2023/02/02 15:25] | TRAIN(e006|iter600): [42/93] Batch: 0.8318 (0.7624) Data: 0.5067 (0.4997) Loss: 0.3374 (0.3645)
[2023/02/02 15:26] | TRAIN(e006|iter650): [92/93] Batch: 0.7856 (0.7711) Data: 0.0496 (0.5027) Loss: 0.4271 (0.3556)
[2023/02/02 15:26] | ------------------------------------------------------------
[2023/02/02 15:26] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:26] | ------------------------------------------------------------
[2023/02/02 15:26] |     TRAIN(6)     0:01:11     0:00:46     0:00:24      0.3556
[2023/02/02 15:26] | ------------------------------------------------------------
[2023/02/02 15:26] | ****************************************************************************************************
[2023/02/02 15:27] | TRAIN(e007|iter700): [49/93] Batch: 0.7866 (0.7771) Data: 0.4712 (0.5101) Loss: 0.3626 (0.3471)
[2023/02/02 15:27] | ------------------------------------------------------------
[2023/02/02 15:27] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:27] | ------------------------------------------------------------
[2023/02/02 15:27] |     TRAIN(7)     0:01:12     0:00:47     0:00:24      0.3398
[2023/02/02 15:27] | ------------------------------------------------------------
[2023/02/02 15:27] | ****************************************************************************************************
[2023/02/02 15:27] | TRAIN(e008|iter750): [ 6/93] Batch: 0.7403 (0.7575) Data: 0.5622 (0.5046) Loss: 0.3233 (0.3481)
[2023/02/02 15:28] | TRAIN(e008|iter800): [56/93] Batch: 0.7348 (0.7689) Data: 0.5369 (0.5072) Loss: 0.3039 (0.3356)
[2023/02/02 15:28] | ------------------------------------------------------------
[2023/02/02 15:28] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:28] | ------------------------------------------------------------
[2023/02/02 15:28] |     TRAIN(8)     0:01:11     0:00:47     0:00:24      0.3236
[2023/02/02 15:28] | ------------------------------------------------------------
[2023/02/02 15:28] | ****************************************************************************************************
[2023/02/02 15:29] | TRAIN(e009|iter850): [13/93] Batch: 0.6789 (0.7537) Data: 0.4181 (0.4862) Loss: 0.2777 (0.3041)
[2023/02/02 15:29] | TRAIN(e009|iter900): [63/93] Batch: 0.7498 (0.7734) Data: 0.5162 (0.5113) Loss: 0.2877 (0.2884)
[2023/02/02 15:30] | ------------------------------------------------------------
[2023/02/02 15:30] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:30] | ------------------------------------------------------------
[2023/02/02 15:30] |     TRAIN(9)     0:01:11     0:00:47     0:00:24      0.2822
[2023/02/02 15:30] | ------------------------------------------------------------
[2023/02/02 15:30] | ****************************************************************************************************
[2023/02/02 15:30] | TRAIN(e010|iter950): [20/93] Batch: 0.7356 (0.7685) Data: 0.4312 (0.5033) Loss: 0.2397 (0.2558)
[2023/02/02 15:30] | TRAIN(e010|iter1000): [70/93] Batch: 0.7646 (0.7844) Data: 0.5138 (0.5202) Loss: 0.2154 (0.2422)
[2023/02/02 15:31] | ------------------------------------------------------------
[2023/02/02 15:31] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:31] | ------------------------------------------------------------
[2023/02/02 15:31] |    TRAIN(10)     0:01:12     0:00:47     0:00:24      0.2404
[2023/02/02 15:31] | ------------------------------------------------------------
[2023/02/02 15:31] | ****************************************************************************************************
[2023/02/02 15:31] | TRAIN(e011|iter1050): [27/93] Batch: 0.7399 (0.7757) Data: 0.4446 (0.5114) Loss: 0.2396 (0.2338)
[2023/02/02 15:32] | TRAIN(e011|iter1100): [77/93] Batch: 0.7164 (0.7700) Data: 0.4717 (0.5080) Loss: 0.2003 (0.2203)
[2023/02/02 15:32] | ------------------------------------------------------------
[2023/02/02 15:32] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:32] | ------------------------------------------------------------
[2023/02/02 15:32] |    TRAIN(11)     0:01:10     0:00:46     0:00:24      0.2164
[2023/02/02 15:32] | ------------------------------------------------------------
[2023/02/02 15:32] | ****************************************************************************************************
[2023/02/02 15:32] | TRAIN(e012|iter1150): [34/93] Batch: 0.7516 (0.7831) Data: 0.5043 (0.5198) Loss: 0.1987 (0.1988)
[2023/02/02 15:33] | TRAIN(e012|iter1200): [84/93] Batch: 0.7504 (0.7806) Data: 0.4745 (0.5174) Loss: 0.1510 (0.1942)
[2023/02/02 15:33] | ------------------------------------------------------------
[2023/02/02 15:33] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:33] | ------------------------------------------------------------
[2023/02/02 15:33] |    TRAIN(12)     0:01:11     0:00:47     0:00:24      0.1930
[2023/02/02 15:33] | ------------------------------------------------------------
[2023/02/02 15:33] | ****************************************************************************************************
[2023/02/02 15:34] | TRAIN(e013|iter1250): [41/93] Batch: 0.7062 (0.7914) Data: 0.5172 (0.5272) Loss: 0.1685 (0.1748)
[2023/02/02 15:34] | TRAIN(e013|iter1300): [91/93] Batch: 1.0698 (0.8007) Data: 0.5379 (0.5366) Loss: 0.1287 (0.1732)
[2023/02/02 15:34] | ------------------------------------------------------------
[2023/02/02 15:34] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:34] | ------------------------------------------------------------
[2023/02/02 15:34] |    TRAIN(13)     0:01:13     0:00:49     0:00:24      0.1736
[2023/02/02 15:34] | ------------------------------------------------------------
[2023/02/02 15:34] | ****************************************************************************************************
[2023/02/02 15:35] | TRAIN(e014|iter1350): [48/93] Batch: 0.7609 (0.7694) Data: 0.4707 (0.5067) Loss: 0.1848 (0.1700)
[2023/02/02 15:36] | ------------------------------------------------------------
[2023/02/02 15:36] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:36] | ------------------------------------------------------------
[2023/02/02 15:36] |    TRAIN(14)     0:01:11     0:00:46     0:00:24      0.1666
[2023/02/02 15:36] | ------------------------------------------------------------
[2023/02/02 15:36] | ****************************************************************************************************
[2023/02/02 15:36] | TRAIN(e015|iter1400): [ 5/93] Batch: 0.7021 (0.7473) Data: 0.5006 (0.4826) Loss: 0.1702 (0.1882)
[2023/02/02 15:36] | TRAIN(e015|iter1450): [55/93] Batch: 0.7848 (0.7824) Data: 0.5292 (0.5192) Loss: 0.1414 (0.1634)
[2023/02/02 15:37] | ------------------------------------------------------------
[2023/02/02 15:37] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:37] | ------------------------------------------------------------
[2023/02/02 15:37] |    TRAIN(15)     0:01:14     0:00:50     0:00:24      0.1574
[2023/02/02 15:37] | ------------------------------------------------------------
[2023/02/02 15:37] | ****************************************************************************************************
[2023/02/02 15:37] | TRAIN(e016|iter1500): [12/93] Batch: 0.8315 (0.8443) Data: 0.6353 (0.5851) Loss: 0.1739 (0.1530)
[2023/02/02 15:38] | TRAIN(e016|iter1550): [62/93] Batch: 0.8011 (0.8659) Data: 0.8708 (0.6057) Loss: 0.1909 (0.1458)
[2023/02/02 15:38] | ------------------------------------------------------------
[2023/02/02 15:38] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:38] | ------------------------------------------------------------
[2023/02/02 15:38] |    TRAIN(16)     0:01:22     0:00:58     0:00:24      0.1456
[2023/02/02 15:38] | ------------------------------------------------------------
[2023/02/02 15:38] | ****************************************************************************************************
[2023/02/02 15:38] | TRAIN(e017|iter1600): [19/93] Batch: 1.0203 (0.9487) Data: 0.5886 (0.6778) Loss: 0.1216 (0.1487)
[2023/02/02 15:39] | TRAIN(e017|iter1650): [69/93] Batch: 0.8772 (0.9942) Data: 1.0742 (0.7330) Loss: 0.1550 (0.1434)
[2023/02/02 15:40] | ------------------------------------------------------------
[2023/02/02 15:40] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:40] | ------------------------------------------------------------
[2023/02/02 15:40] |    TRAIN(17)     0:01:31     0:01:06     0:00:24      0.1426
[2023/02/02 15:40] | ------------------------------------------------------------
[2023/02/02 15:40] | ****************************************************************************************************
[2023/02/02 15:40] | TRAIN(e018|iter1700): [26/93] Batch: 1.0289 (0.9407) Data: 0.5993 (0.6718) Loss: 0.1958 (0.1323)
[2023/02/02 15:41] | TRAIN(e018|iter1750): [76/93] Batch: 1.1259 (0.9357) Data: 0.6844 (0.6704) Loss: 0.1032 (0.1336)
[2023/02/02 15:41] | ------------------------------------------------------------
[2023/02/02 15:41] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:41] | ------------------------------------------------------------
[2023/02/02 15:41] |    TRAIN(18)     0:01:26     0:01:01     0:00:24      0.1329
[2023/02/02 15:41] | ------------------------------------------------------------
[2023/02/02 15:41] | ****************************************************************************************************
[2023/02/02 15:42] | TRAIN(e019|iter1800): [33/93] Batch: 0.9359 (0.8826) Data: 0.7406 (0.6219) Loss: 0.1286 (0.1343)
[2023/02/02 15:42] | TRAIN(e019|iter1850): [83/93] Batch: 1.1540 (0.9505) Data: 0.9169 (0.6873) Loss: 0.1183 (0.1321)
[2023/02/02 15:43] | ------------------------------------------------------------
[2023/02/02 15:43] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:43] | ------------------------------------------------------------
[2023/02/02 15:43] |    TRAIN(19)     0:01:28     0:01:03     0:00:24      0.1322
[2023/02/02 15:43] | ------------------------------------------------------------
[2023/02/02 15:43] | ****************************************************************************************************
[2023/02/02 15:43] | TRAIN(e020|iter1900): [40/93] Batch: 0.7642 (0.8921) Data: 0.5878 (0.6260) Loss: 0.1369 (0.1232)
[2023/02/02 15:44] | TRAIN(e020|iter1950): [90/93] Batch: 0.7778 (0.9024) Data: 0.5933 (0.6362) Loss: 0.1403 (0.1231)
[2023/02/02 15:44] | ------------------------------------------------------------
[2023/02/02 15:44] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:44] | ------------------------------------------------------------
[2023/02/02 15:44] |    TRAIN(20)     0:01:23     0:00:58     0:00:24      0.1235
[2023/02/02 15:44] | ------------------------------------------------------------
[2023/02/02 15:44] | ****************************************************************************************************
[2023/02/02 15:45] | TRAIN(e021|iter2000): [47/93] Batch: 0.8925 (0.9171) Data: 0.5709 (0.6483) Loss: 0.1545 (0.1245)
[2023/02/02 15:45] | ------------------------------------------------------------
[2023/02/02 15:45] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:45] | ------------------------------------------------------------
[2023/02/02 15:45] |    TRAIN(21)     0:01:24     0:00:59     0:00:24      0.1224
[2023/02/02 15:45] | ------------------------------------------------------------
[2023/02/02 15:45] | ****************************************************************************************************
[2023/02/02 15:45] | TRAIN(e022|iter2050): [ 4/93] Batch: 0.7953 (0.8744) Data: 0.8722 (0.6615) Loss: 0.1211 (0.1194)
[2023/02/02 15:46] | TRAIN(e022|iter2100): [54/93] Batch: 0.7872 (0.9154) Data: 0.8161 (0.6524) Loss: 0.1250 (0.1224)
[2023/02/02 15:47] | ------------------------------------------------------------
[2023/02/02 15:47] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:47] | ------------------------------------------------------------
[2023/02/02 15:47] |    TRAIN(22)     0:01:23     0:00:59     0:00:24      0.1224
[2023/02/02 15:47] | ------------------------------------------------------------
[2023/02/02 15:47] | ****************************************************************************************************
[2023/02/02 15:47] | TRAIN(e023|iter2150): [11/93] Batch: 1.3110 (0.9265) Data: 0.6361 (0.6586) Loss: 0.0872 (0.1150)
[2023/02/02 15:48] | TRAIN(e023|iter2200): [61/93] Batch: 0.9062 (0.9536) Data: 0.8046 (0.6878) Loss: 0.0841 (0.1102)
[2023/02/02 15:48] | ------------------------------------------------------------
[2023/02/02 15:48] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:48] | ------------------------------------------------------------
[2023/02/02 15:48] |    TRAIN(23)     0:01:26     0:01:02     0:00:24      0.1092
[2023/02/02 15:48] | ------------------------------------------------------------
[2023/02/02 15:48] | ****************************************************************************************************
[2023/02/02 15:49] | TRAIN(e024|iter2250): [18/93] Batch: 0.8362 (0.9319) Data: 0.8118 (0.6734) Loss: 0.1152 (0.1237)
[2023/02/02 15:49] | TRAIN(e024|iter2300): [68/93] Batch: 0.7887 (0.9852) Data: 0.5386 (0.7154) Loss: 0.0862 (0.1043)
[2023/02/02 15:50] | ------------------------------------------------------------
[2023/02/02 15:50] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:50] | ------------------------------------------------------------
[2023/02/02 15:50] |    TRAIN(24)     0:01:30     0:01:05     0:00:24      0.1028
[2023/02/02 15:50] | ------------------------------------------------------------
[2023/02/02 15:50] | ****************************************************************************************************
[2023/02/02 15:50] | TRAIN(e025|iter2350): [25/93] Batch: 0.9824 (0.9447) Data: 0.4966 (0.6718) Loss: 0.1132 (0.1059)
[2023/02/02 15:51] | TRAIN(e025|iter2400): [75/93] Batch: 0.9166 (0.9699) Data: 0.5961 (0.6997) Loss: 0.1161 (0.1043)
[2023/02/02 15:51] | ------------------------------------------------------------
[2023/02/02 15:51] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:51] | ------------------------------------------------------------
[2023/02/02 15:51] |    TRAIN(25)     0:01:27     0:01:02     0:00:24      0.1029
[2023/02/02 15:51] | ------------------------------------------------------------
[2023/02/02 15:51] | ****************************************************************************************************
[2023/02/02 15:52] | TRAIN(e026|iter2450): [32/93] Batch: 0.8124 (0.8208) Data: 0.4946 (0.5543) Loss: 0.1282 (0.0979)
[2023/02/02 15:52] | TRAIN(e026|iter2500): [82/93] Batch: 0.8180 (0.8122) Data: 0.5574 (0.5485) Loss: 0.1336 (0.1030)
[2023/02/02 15:52] | ------------------------------------------------------------
[2023/02/02 15:52] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:52] | ------------------------------------------------------------
[2023/02/02 15:52] |    TRAIN(26)     0:01:15     0:00:51     0:00:24      0.1032
[2023/02/02 15:52] | ------------------------------------------------------------
[2023/02/02 15:52] | ****************************************************************************************************
[2023/02/02 15:53] | TRAIN(e027|iter2550): [39/93] Batch: 0.7456 (0.9154) Data: 0.5284 (0.6463) Loss: 0.0790 (0.0978)
[2023/02/02 15:54] | TRAIN(e027|iter2600): [89/93] Batch: 0.8265 (0.8795) Data: 0.5132 (0.6112) Loss: 0.0764 (0.0961)
[2023/02/02 15:54] | ------------------------------------------------------------
[2023/02/02 15:54] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:54] | ------------------------------------------------------------
[2023/02/02 15:54] |    TRAIN(27)     0:01:20     0:00:56     0:00:24      0.0966
[2023/02/02 15:54] | ------------------------------------------------------------
[2023/02/02 15:54] | ****************************************************************************************************
[2023/02/02 15:54] | TRAIN(e028|iter2650): [46/93] Batch: 0.8006 (0.7784) Data: 0.5353 (0.5163) Loss: 0.0701 (0.0925)
[2023/02/02 15:55] | ------------------------------------------------------------
[2023/02/02 15:55] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:55] | ------------------------------------------------------------
[2023/02/02 15:55] |    TRAIN(28)     0:01:12     0:00:48     0:00:24      0.0910
[2023/02/02 15:55] | ------------------------------------------------------------
[2023/02/02 15:55] | ****************************************************************************************************
[2023/02/02 15:55] | TRAIN(e029|iter2700): [ 3/93] Batch: 0.7993 (0.7848) Data: 0.4985 (0.5150) Loss: 0.0972 (0.0933)
[2023/02/02 15:56] | TRAIN(e029|iter2750): [53/93] Batch: 0.7643 (0.7776) Data: 0.5401 (0.5150) Loss: 0.1132 (0.0904)
[2023/02/02 15:56] | ------------------------------------------------------------
[2023/02/02 15:56] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:56] | ------------------------------------------------------------
[2023/02/02 15:56] |    TRAIN(29)     0:01:11     0:00:47     0:00:24      0.0889
[2023/02/02 15:56] | ------------------------------------------------------------
[2023/02/02 15:56] | ****************************************************************************************************
[2023/02/02 15:56] | TRAIN(e030|iter2800): [10/93] Batch: 0.9548 (0.8170) Data: 0.4856 (0.5468) Loss: 0.1149 (0.0806)
[2023/02/02 15:57] | TRAIN(e030|iter2850): [60/93] Batch: 0.7499 (0.8178) Data: 0.7101 (0.5572) Loss: 0.0752 (0.0878)
[2023/02/02 15:57] | ------------------------------------------------------------
[2023/02/02 15:57] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:57] | ------------------------------------------------------------
[2023/02/02 15:57] |    TRAIN(30)     0:01:14     0:00:50     0:00:24      0.0865
[2023/02/02 15:57] | ------------------------------------------------------------
[2023/02/02 15:57] | ****************************************************************************************************
[2023/02/02 15:58] | TRAIN(e031|iter2900): [17/93] Batch: 0.7836 (0.7605) Data: 0.7619 (0.5132) Loss: 0.0979 (0.0859)
[2023/02/02 15:58] | TRAIN(e031|iter2950): [67/93] Batch: 0.8273 (0.8030) Data: 0.5261 (0.5390) Loss: 0.0722 (0.0852)
[2023/02/02 15:59] | ------------------------------------------------------------
[2023/02/02 15:59] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 15:59] | ------------------------------------------------------------
[2023/02/02 15:59] |    TRAIN(31)     0:01:14     0:00:50     0:00:24      0.0846
[2023/02/02 15:59] | ------------------------------------------------------------
[2023/02/02 15:59] | ****************************************************************************************************
[2023/02/02 15:59] | TRAIN(e032|iter3000): [24/93] Batch: 0.7382 (0.7941) Data: 0.4958 (0.5280) Loss: 0.0712 (0.0799)
[2023/02/02 16:00] | TRAIN(e032|iter3050): [74/93] Batch: 0.7897 (0.8132) Data: 0.5267 (0.5490) Loss: 0.0583 (0.0801)
[2023/02/02 16:00] | ------------------------------------------------------------
[2023/02/02 16:00] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:00] | ------------------------------------------------------------
[2023/02/02 16:00] |    TRAIN(32)     0:01:14     0:00:50     0:00:24      0.0796
[2023/02/02 16:00] | ------------------------------------------------------------
[2023/02/02 16:00] | ****************************************************************************************************
[2023/02/02 16:00] | TRAIN(e033|iter3100): [31/93] Batch: 0.7305 (0.8063) Data: 0.5280 (0.5424) Loss: 0.0709 (0.0728)
[2023/02/02 16:01] | TRAIN(e033|iter3150): [81/93] Batch: 0.8056 (0.8033) Data: 0.5436 (0.5402) Loss: 0.1157 (0.0826)
[2023/02/02 16:01] | ------------------------------------------------------------
[2023/02/02 16:01] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:01] | ------------------------------------------------------------
[2023/02/02 16:01] |    TRAIN(33)     0:01:13     0:00:49     0:00:24      0.0828
[2023/02/02 16:01] | ------------------------------------------------------------
[2023/02/02 16:01] | ****************************************************************************************************
[2023/02/02 16:02] | TRAIN(e034|iter3200): [38/93] Batch: 0.8178 (0.7849) Data: 0.4796 (0.5191) Loss: 0.0667 (0.0769)
[2023/02/02 16:02] | TRAIN(e034|iter3250): [88/93] Batch: 0.7849 (0.8083) Data: 0.6046 (0.5444) Loss: 0.0625 (0.0759)
[2023/02/02 16:02] | ------------------------------------------------------------
[2023/02/02 16:02] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:02] | ------------------------------------------------------------
[2023/02/02 16:02] |    TRAIN(34)     0:01:14     0:00:50     0:00:24      0.0759
[2023/02/02 16:02] | ------------------------------------------------------------
[2023/02/02 16:02] | ****************************************************************************************************
[2023/02/02 16:03] | TRAIN(e035|iter3300): [45/93] Batch: 0.8308 (0.8313) Data: 0.4749 (0.5660) Loss: 0.0600 (0.0695)
[2023/02/02 16:04] | ------------------------------------------------------------
[2023/02/02 16:04] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:04] | ------------------------------------------------------------
[2023/02/02 16:04] |    TRAIN(35)     0:01:14     0:00:50     0:00:24      0.0761
[2023/02/02 16:04] | ------------------------------------------------------------
[2023/02/02 16:04] | ****************************************************************************************************
[2023/02/02 16:04] | TRAIN(e036|iter3350): [ 2/93] Batch: 0.7897 (0.7940) Data: 0.5246 (0.5300) Loss: 0.0629 (0.0871)
[2023/02/02 16:04] | TRAIN(e036|iter3400): [52/93] Batch: 0.8287 (0.8468) Data: 0.5274 (0.5806) Loss: 0.0656 (0.0705)
[2023/02/02 16:05] | ------------------------------------------------------------
[2023/02/02 16:05] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:05] | ------------------------------------------------------------
[2023/02/02 16:05] |    TRAIN(36)     0:01:16     0:00:52     0:00:24      0.0701
[2023/02/02 16:05] | ------------------------------------------------------------
[2023/02/02 16:05] | ****************************************************************************************************
[2023/02/02 16:05] | TRAIN(e037|iter3450): [ 9/93] Batch: 0.7993 (0.8196) Data: 0.5138 (0.5529) Loss: 0.0530 (0.0634)
[2023/02/02 16:06] | TRAIN(e037|iter3500): [59/93] Batch: 0.7751 (0.8191) Data: 0.5249 (0.5546) Loss: 0.0609 (0.0662)
[2023/02/02 16:06] | ------------------------------------------------------------
[2023/02/02 16:06] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:06] | ------------------------------------------------------------
[2023/02/02 16:06] |    TRAIN(37)     0:01:14     0:00:50     0:00:24      0.0682
[2023/02/02 16:06] | ------------------------------------------------------------
[2023/02/02 16:06] | ****************************************************************************************************
[2023/02/02 16:06] | TRAIN(e038|iter3550): [16/93] Batch: 0.8119 (0.8035) Data: 0.4807 (0.5362) Loss: 0.0615 (0.0737)
[2023/02/02 16:07] | TRAIN(e038|iter3600): [66/93] Batch: 0.7932 (0.7999) Data: 0.5471 (0.5368) Loss: 0.1307 (0.0785)
[2023/02/02 16:07] | ------------------------------------------------------------
[2023/02/02 16:07] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:07] | ------------------------------------------------------------
[2023/02/02 16:07] |    TRAIN(38)     0:01:13     0:00:49     0:00:24      0.0796
[2023/02/02 16:07] | ------------------------------------------------------------
[2023/02/02 16:07] | ****************************************************************************************************
[2023/02/02 16:08] | TRAIN(e039|iter3650): [23/93] Batch: 0.8022 (0.7850) Data: 0.4896 (0.5208) Loss: 0.0601 (0.0736)
[2023/02/02 16:08] | TRAIN(e039|iter3700): [73/93] Batch: 0.7423 (0.7829) Data: 0.5795 (0.5207) Loss: 0.0629 (0.0703)
[2023/02/02 16:09] | ------------------------------------------------------------
[2023/02/02 16:09] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:09] | ------------------------------------------------------------
[2023/02/02 16:09] |    TRAIN(39)     0:01:11     0:00:47     0:00:24      0.0706
[2023/02/02 16:09] | ------------------------------------------------------------
[2023/02/02 16:09] | ====================================================================================================
[2023/02/02 16:11] | idx 0 case case0008 mean_dice 0.568723 mean_hd95 64.340810
[2023/02/02 16:12] | idx 1 case case0022 mean_dice 0.826516 mean_hd95 34.367058
[2023/02/02 16:13] | idx 2 case case0038 mean_dice 0.636041 mean_hd95 101.181835
[2023/02/02 16:16] | idx 3 case case0036 mean_dice 0.686723 mean_hd95 101.124744
[2023/02/02 16:18] | idx 4 case case0032 mean_dice 0.730163 mean_hd95 55.765552
[2023/02/02 16:19] | idx 5 case case0002 mean_dice 0.787398 mean_hd95 53.080508
[2023/02/02 16:21] | idx 6 case case0029 mean_dice 0.675987 mean_hd95 68.174617
[2023/02/02 16:23] | idx 7 case case0003 mean_dice 0.553111 mean_hd95 122.410637
[2023/02/02 16:25] | idx 8 case case0001 mean_dice 0.721217 mean_hd95 79.525943
[2023/02/02 16:27] | idx 9 case case0004 mean_dice 0.732768 mean_hd95 44.041797
[2023/02/02 16:28] | idx 10 case case0025 mean_dice 0.738934 mean_hd95 51.458017
[2023/02/02 16:29] | idx 11 case case0035 mean_dice 0.779844 mean_hd95 40.779128
[2023/02/02 16:29] | Mean class 1 mean_dice 0.860603 mean_hd95 27.309050
[2023/02/02 16:29] | Mean class 2 mean_dice 0.551183 mean_hd95 96.589472
[2023/02/02 16:29] | Mean class 3 mean_dice 0.745748 mean_hd95 113.902988
[2023/02/02 16:29] | Mean class 4 mean_dice 0.678684 mean_hd95 65.757013
[2023/02/02 16:29] | Mean class 5 mean_dice 0.899434 mean_hd95 60.447530
[2023/02/02 16:29] | Mean class 6 mean_dice 0.496123 mean_hd95 20.041562
[2023/02/02 16:29] | Mean class 7 mean_dice 0.788746 mean_hd95 113.560858
[2023/02/02 16:29] | Mean class 8 mean_dice 0.604428 mean_hd95 46.558624
[2023/02/02 16:29] | Testing performance>>  mean_dice : 0.703119  mean_hd95 : 68.020887
[2023/02/02 16:29] | ====================================================================================================
[2023/02/02 16:29] | >>>>> best model is changed <<<<<
[2023/02/02 16:29] | ****************************************************************************************************
[2023/02/02 16:30] | TRAIN(e040|iter3750): [30/93] Batch: 0.7682 (0.7644) Data: 0.4737 (0.5034) Loss: 0.0748 (0.0701)
[2023/02/02 16:30] | TRAIN(e040|iter3800): [80/93] Batch: 0.7934 (0.7692) Data: 0.5536 (0.5102) Loss: 0.0672 (0.0681)
[2023/02/02 16:30] | ------------------------------------------------------------
[2023/02/02 16:30] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:30] | ------------------------------------------------------------
[2023/02/02 16:30] |    TRAIN(40)     0:01:11     0:00:47     0:00:24      0.0680
[2023/02/02 16:30] | ------------------------------------------------------------
[2023/02/02 16:30] | ****************************************************************************************************
[2023/02/02 16:31] | TRAIN(e041|iter3850): [37/93] Batch: 0.8170 (0.7911) Data: 0.4945 (0.5304) Loss: 0.0697 (0.0714)
[2023/02/02 16:32] | TRAIN(e041|iter3900): [87/93] Batch: 0.7783 (0.7866) Data: 0.5290 (0.5260) Loss: 0.0587 (0.0693)
[2023/02/02 16:32] | ------------------------------------------------------------
[2023/02/02 16:32] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:32] | ------------------------------------------------------------
[2023/02/02 16:32] |    TRAIN(41)     0:01:12     0:00:48     0:00:24      0.0698
[2023/02/02 16:32] | ------------------------------------------------------------
[2023/02/02 16:32] | ****************************************************************************************************
[2023/02/02 16:32] | TRAIN(e042|iter3950): [44/93] Batch: 0.7804 (0.7909) Data: 0.5171 (0.5290) Loss: 0.0477 (0.0662)
[2023/02/02 16:33] | ------------------------------------------------------------
[2023/02/02 16:33] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:33] | ------------------------------------------------------------
[2023/02/02 16:33] |    TRAIN(42)     0:01:16     0:00:52     0:00:24      0.0670
[2023/02/02 16:33] | ------------------------------------------------------------
[2023/02/02 16:33] | ****************************************************************************************************
[2023/02/02 16:33] | TRAIN(e043|iter4000): [ 1/93] Batch: 0.7681 (0.7681) Data: 0.5265 (0.5143) Loss: 0.0515 (0.0560)
[2023/02/02 16:34] | TRAIN(e043|iter4050): [51/93] Batch: 0.7865 (0.8507) Data: 0.5052 (0.5848) Loss: 0.0537 (0.0633)
[2023/02/02 16:34] | ------------------------------------------------------------
[2023/02/02 16:34] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:34] | ------------------------------------------------------------
[2023/02/02 16:34] |    TRAIN(43)     0:01:17     0:00:53     0:00:24      0.0620
[2023/02/02 16:34] | ------------------------------------------------------------
[2023/02/02 16:34] | ****************************************************************************************************
[2023/02/02 16:34] | TRAIN(e044|iter4100): [ 8/93] Batch: 0.9334 (0.9651) Data: 0.6205 (0.6937) Loss: 0.0514 (0.0597)
[2023/02/02 16:35] | TRAIN(e044|iter4150): [58/93] Batch: 0.9348 (0.8350) Data: 0.5052 (0.5708) Loss: 0.0492 (0.0614)
[2023/02/02 16:35] | ------------------------------------------------------------
[2023/02/02 16:35] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:35] | ------------------------------------------------------------
[2023/02/02 16:35] |    TRAIN(44)     0:01:16     0:00:52     0:00:24      0.0631
[2023/02/02 16:35] | ------------------------------------------------------------
[2023/02/02 16:35] | ****************************************************************************************************
[2023/02/02 16:36] | TRAIN(e045|iter4200): [15/93] Batch: 0.7998 (0.8232) Data: 0.5096 (0.5564) Loss: 0.0712 (0.0846)
[2023/02/02 16:36] | TRAIN(e045|iter4250): [65/93] Batch: 0.7846 (0.7962) Data: 0.4937 (0.5324) Loss: 0.0573 (0.0722)
[2023/02/02 16:37] | ------------------------------------------------------------
[2023/02/02 16:37] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:37] | ------------------------------------------------------------
[2023/02/02 16:37] |    TRAIN(45)     0:01:14     0:00:50     0:00:24      0.0705
[2023/02/02 16:37] | ------------------------------------------------------------
[2023/02/02 16:37] | ****************************************************************************************************
[2023/02/02 16:37] | TRAIN(e046|iter4300): [22/93] Batch: 1.0278 (0.8543) Data: 0.5496 (0.5885) Loss: 0.0709 (0.0624)
[2023/02/02 16:38] | TRAIN(e046|iter4350): [72/93] Batch: 0.7725 (0.8230) Data: 0.5773 (0.5599) Loss: 0.1526 (0.0657)
[2023/02/02 16:38] | ------------------------------------------------------------
[2023/02/02 16:38] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:38] | ------------------------------------------------------------
[2023/02/02 16:38] |    TRAIN(46)     0:01:16     0:00:51     0:00:24      0.0661
[2023/02/02 16:38] | ------------------------------------------------------------
[2023/02/02 16:38] | ****************************************************************************************************
[2023/02/02 16:38] | TRAIN(e047|iter4400): [29/93] Batch: 0.8291 (0.7930) Data: 0.7030 (0.5366) Loss: 0.0594 (0.0755)
[2023/02/02 16:39] | TRAIN(e047|iter4450): [79/93] Batch: 0.9473 (0.8186) Data: 0.6724 (0.5572) Loss: 0.1018 (0.0691)
[2023/02/02 16:39] | ------------------------------------------------------------
[2023/02/02 16:39] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:39] | ------------------------------------------------------------
[2023/02/02 16:39] |    TRAIN(47)     0:01:15     0:00:50     0:00:24      0.0686
[2023/02/02 16:39] | ------------------------------------------------------------
[2023/02/02 16:39] | ****************************************************************************************************
[2023/02/02 16:40] | TRAIN(e048|iter4500): [36/93] Batch: 0.7145 (0.8054) Data: 0.5216 (0.5416) Loss: 0.0457 (0.0569)
[2023/02/02 16:40] | TRAIN(e048|iter4550): [86/93] Batch: 0.8111 (0.8145) Data: 0.4843 (0.5502) Loss: 0.0715 (0.0601)
[2023/02/02 16:40] | ------------------------------------------------------------
[2023/02/02 16:40] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:40] | ------------------------------------------------------------
[2023/02/02 16:40] |    TRAIN(48)     0:01:15     0:00:50     0:00:24      0.0600
[2023/02/02 16:40] | ------------------------------------------------------------
[2023/02/02 16:40] | ****************************************************************************************************
[2023/02/02 16:41] | TRAIN(e049|iter4600): [43/93] Batch: 0.7854 (0.8169) Data: 0.4926 (0.5525) Loss: 0.0603 (0.0645)
[2023/02/02 16:42] | ------------------------------------------------------------
[2023/02/02 16:42] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 16:42] | ------------------------------------------------------------
[2023/02/02 16:42] |    TRAIN(49)     0:01:14     0:00:50     0:00:24      0.0623
[2023/02/02 16:42] | ------------------------------------------------------------
[2023/02/02 16:42] | ====================================================================================================
[2023/02/02 16:44] | idx 0 case case0008 mean_dice 0.599615 mean_hd95 39.811933
[2023/02/02 16:45] | idx 1 case case0022 mean_dice 0.843776 mean_hd95 45.060578
[2023/02/02 16:46] | idx 2 case case0038 mean_dice 0.693866 mean_hd95 80.358842
[2023/02/02 16:48] | idx 3 case case0036 mean_dice 0.758773 mean_hd95 53.857907
[2023/02/02 16:50] | idx 4 case case0032 mean_dice 0.732970 mean_hd95 28.813666
[2023/02/02 16:52] | idx 5 case case0002 mean_dice 0.819727 mean_hd95 46.316756
[2023/02/02 16:53] | idx 6 case case0029 mean_dice 0.761711 mean_hd95 41.210479
[2023/02/02 16:56] | idx 7 case case0003 mean_dice 0.563077 mean_hd95 126.262290
[2023/02/02 16:58] | idx 8 case case0001 mean_dice 0.710558 mean_hd95 72.662535
[2023/02/02 16:59] | idx 9 case case0004 mean_dice 0.780498 mean_hd95 36.767043
[2023/02/02 17:01] | idx 10 case case0025 mean_dice 0.788027 mean_hd95 51.432963
[2023/02/02 17:01] | idx 11 case case0035 mean_dice 0.827236 mean_hd95 35.702458
[2023/02/02 17:01] | Mean class 1 mean_dice 0.869476 mean_hd95 17.917901
[2023/02/02 17:01] | Mean class 2 mean_dice 0.566895 mean_hd95 59.201837
[2023/02/02 17:01] | Mean class 3 mean_dice 0.764971 mean_hd95 93.786743
[2023/02/02 17:01] | Mean class 4 mean_dice 0.761156 mean_hd95 88.421915
[2023/02/02 17:01] | Mean class 5 mean_dice 0.917231 mean_hd95 40.744617
[2023/02/02 17:01] | Mean class 6 mean_dice 0.568178 mean_hd95 23.714838
[2023/02/02 17:01] | Mean class 7 mean_dice 0.769344 mean_hd95 92.169954
[2023/02/02 17:01] | Mean class 8 mean_dice 0.702637 mean_hd95 22.880496
[2023/02/02 17:01] | Testing performance>>  mean_dice : 0.739986  mean_hd95 : 54.854788
[2023/02/02 17:01] | ====================================================================================================
[2023/02/02 17:01] | >>>>> best model is changed <<<<<
[2023/02/02 17:01] | ****************************************************************************************************
[2023/02/02 17:02] | TRAIN(e050|iter4650): [ 0/93] Batch: 0.0000 (0.0000) Data: 0.7426 (0.7426) Loss: 0.0539 (0.0539)
[2023/02/02 17:02] | TRAIN(e050|iter4700): [50/93] Batch: 0.7397 (0.7785) Data: 0.5630 (0.5205) Loss: 0.0558 (0.0572)
[2023/02/02 17:03] | ------------------------------------------------------------
[2023/02/02 17:03] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:03] | ------------------------------------------------------------
[2023/02/02 17:03] |    TRAIN(50)     0:01:11     0:00:47     0:00:23      0.0567
[2023/02/02 17:03] | ------------------------------------------------------------
[2023/02/02 17:03] | ****************************************************************************************************
[2023/02/02 17:03] | TRAIN(e051|iter4750): [ 7/93] Batch: 0.8553 (0.7835) Data: 0.5422 (0.5256) Loss: 0.0516 (0.0587)
[2023/02/02 17:03] | TRAIN(e051|iter4800): [57/93] Batch: 0.7329 (0.7856) Data: 0.4423 (0.5208) Loss: 0.0969 (0.0589)
[2023/02/02 17:04] | ------------------------------------------------------------
[2023/02/02 17:04] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:04] | ------------------------------------------------------------
[2023/02/02 17:04] |    TRAIN(51)     0:01:12     0:00:48     0:00:24      0.0595
[2023/02/02 17:04] | ------------------------------------------------------------
[2023/02/02 17:04] | ****************************************************************************************************
[2023/02/02 17:04] | TRAIN(e052|iter4850): [14/93] Batch: 0.7518 (0.7892) Data: 0.5528 (0.5282) Loss: 0.0372 (0.0590)
[2023/02/02 17:05] | TRAIN(e052|iter4900): [64/93] Batch: 0.7177 (0.8087) Data: 0.5047 (0.5441) Loss: 0.0335 (0.0517)
[2023/02/02 17:05] | ------------------------------------------------------------
[2023/02/02 17:05] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:05] | ------------------------------------------------------------
[2023/02/02 17:05] |    TRAIN(52)     0:01:14     0:00:50     0:00:24      0.0544
[2023/02/02 17:05] | ------------------------------------------------------------
[2023/02/02 17:05] | ****************************************************************************************************
[2023/02/02 17:05] | TRAIN(e053|iter4950): [21/93] Batch: 0.7788 (0.8088) Data: 0.6755 (0.5521) Loss: 0.0607 (0.0570)
[2023/02/02 17:06] | TRAIN(e053|iter5000): [71/93] Batch: 0.7386 (0.8225) Data: 0.5307 (0.5587) Loss: 0.0986 (0.0596)
[2023/02/02 17:06] | ------------------------------------------------------------
[2023/02/02 17:06] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:06] | ------------------------------------------------------------
[2023/02/02 17:06] |    TRAIN(53)     0:01:15     0:00:51     0:00:24      0.0596
[2023/02/02 17:06] | ------------------------------------------------------------
[2023/02/02 17:06] | ****************************************************************************************************
[2023/02/02 17:07] | TRAIN(e054|iter5050): [28/93] Batch: 0.7324 (0.8002) Data: 0.5254 (0.5365) Loss: 0.0545 (0.0646)
[2023/02/02 17:07] | TRAIN(e054|iter5100): [78/93] Batch: 0.7814 (0.8083) Data: 0.5542 (0.5447) Loss: 0.0533 (0.0594)
[2023/02/02 17:08] | ------------------------------------------------------------
[2023/02/02 17:08] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:08] | ------------------------------------------------------------
[2023/02/02 17:08] |    TRAIN(54)     0:01:15     0:00:50     0:00:24      0.0584
[2023/02/02 17:08] | ------------------------------------------------------------
[2023/02/02 17:08] | ****************************************************************************************************
[2023/02/02 17:08] | TRAIN(e055|iter5150): [35/93] Batch: 0.8478 (0.8203) Data: 0.7142 (0.5601) Loss: 0.0440 (0.0617)
[2023/02/02 17:09] | TRAIN(e055|iter5200): [85/93] Batch: 0.7831 (0.8226) Data: 0.4912 (0.5575) Loss: 0.0666 (0.0610)
[2023/02/02 17:09] | ------------------------------------------------------------
[2023/02/02 17:09] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:09] | ------------------------------------------------------------
[2023/02/02 17:09] |    TRAIN(55)     0:01:16     0:00:51     0:00:24      0.0614
[2023/02/02 17:09] | ------------------------------------------------------------
[2023/02/02 17:09] | ****************************************************************************************************
[2023/02/02 17:10] | TRAIN(e056|iter5250): [42/93] Batch: 1.0251 (0.8137) Data: 0.5262 (0.5486) Loss: 0.1029 (0.0537)
[2023/02/02 17:10] | TRAIN(e056|iter5300): [92/93] Batch: 0.8573 (0.8226) Data: 0.0485 (0.5529) Loss: 0.0935 (0.0529)
[2023/02/02 17:10] | ------------------------------------------------------------
[2023/02/02 17:10] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:10] | ------------------------------------------------------------
[2023/02/02 17:10] |    TRAIN(56)     0:01:15     0:00:51     0:00:24      0.0529
[2023/02/02 17:10] | ------------------------------------------------------------
[2023/02/02 17:10] | ****************************************************************************************************
[2023/02/02 17:11] | TRAIN(e057|iter5350): [49/93] Batch: 0.7585 (0.8062) Data: 0.5966 (0.5442) Loss: 0.0514 (0.0587)
[2023/02/02 17:11] | ------------------------------------------------------------
[2023/02/02 17:11] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:11] | ------------------------------------------------------------
[2023/02/02 17:11] |    TRAIN(57)     0:01:14     0:00:50     0:00:24      0.0582
[2023/02/02 17:11] | ------------------------------------------------------------
[2023/02/02 17:11] | ****************************************************************************************************
[2023/02/02 17:12] | TRAIN(e058|iter5400): [ 6/93] Batch: 0.7611 (0.8218) Data: 0.5792 (0.5626) Loss: 0.0379 (0.0420)
[2023/02/02 17:12] | TRAIN(e058|iter5450): [56/93] Batch: 0.7694 (0.7853) Data: 0.5297 (0.5224) Loss: 0.0608 (0.0521)
[2023/02/02 17:13] | ------------------------------------------------------------
[2023/02/02 17:13] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:13] | ------------------------------------------------------------
[2023/02/02 17:13] |    TRAIN(58)     0:01:13     0:00:48     0:00:24      0.0490
[2023/02/02 17:13] | ------------------------------------------------------------
[2023/02/02 17:13] | ****************************************************************************************************
[2023/02/02 17:13] | TRAIN(e059|iter5500): [13/93] Batch: 0.8896 (0.7842) Data: 0.5733 (0.5244) Loss: 0.0425 (0.0571)
[2023/02/02 17:14] | TRAIN(e059|iter5550): [63/93] Batch: 0.7841 (0.8006) Data: 0.5210 (0.5374) Loss: 0.0876 (0.0564)
[2023/02/02 17:14] | ------------------------------------------------------------
[2023/02/02 17:14] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:14] | ------------------------------------------------------------
[2023/02/02 17:14] |    TRAIN(59)     0:01:14     0:00:50     0:00:24      0.0564
[2023/02/02 17:14] | ------------------------------------------------------------
[2023/02/02 17:14] | ====================================================================================================
[2023/02/02 17:16] | idx 0 case case0008 mean_dice 0.591752 mean_hd95 44.850437
[2023/02/02 17:17] | idx 1 case case0022 mean_dice 0.862415 mean_hd95 31.362751
[2023/02/02 17:18] | idx 2 case case0038 mean_dice 0.746884 mean_hd95 72.323836
[2023/02/02 17:21] | idx 3 case case0036 mean_dice 0.756258 mean_hd95 49.002877
[2023/02/02 17:22] | idx 4 case case0032 mean_dice 0.761820 mean_hd95 25.289690
[2023/02/02 17:24] | idx 5 case case0002 mean_dice 0.834854 mean_hd95 38.163075
[2023/02/02 17:25] | idx 6 case case0029 mean_dice 0.776888 mean_hd95 40.330266
[2023/02/02 17:28] | idx 7 case case0003 mean_dice 0.554683 mean_hd95 125.314415
[2023/02/02 17:30] | idx 8 case case0001 mean_dice 0.740835 mean_hd95 71.826450
[2023/02/02 17:32] | idx 9 case case0004 mean_dice 0.781556 mean_hd95 36.169068
[2023/02/02 17:33] | idx 10 case case0025 mean_dice 0.734882 mean_hd95 49.180006
[2023/02/02 17:34] | idx 11 case case0035 mean_dice 0.837825 mean_hd95 34.183655
[2023/02/02 17:34] | Mean class 1 mean_dice 0.870461 mean_hd95 16.187542
[2023/02/02 17:34] | Mean class 2 mean_dice 0.636578 mean_hd95 40.139376
[2023/02/02 17:34] | Mean class 3 mean_dice 0.751335 mean_hd95 100.337566
[2023/02/02 17:34] | Mean class 4 mean_dice 0.702130 mean_hd95 105.711776
[2023/02/02 17:34] | Mean class 5 mean_dice 0.934823 mean_hd95 28.435738
[2023/02/02 17:34] | Mean class 6 mean_dice 0.590553 mean_hd95 22.503913
[2023/02/02 17:34] | Mean class 7 mean_dice 0.795708 mean_hd95 74.007555
[2023/02/02 17:34] | Mean class 8 mean_dice 0.705514 mean_hd95 24.674219
[2023/02/02 17:34] | Testing performance>>  mean_dice : 0.748388  mean_hd95 : 51.499711
[2023/02/02 17:34] | ====================================================================================================
[2023/02/02 17:34] | >>>>> best model is changed <<<<<
[2023/02/02 17:34] | ****************************************************************************************************
[2023/02/02 17:34] | TRAIN(e060|iter5600): [20/93] Batch: 0.7535 (0.8067) Data: 0.5452 (0.5479) Loss: 0.0432 (0.0472)
[2023/02/02 17:35] | TRAIN(e060|iter5650): [70/93] Batch: 0.7305 (0.8029) Data: 0.5775 (0.5435) Loss: 0.0524 (0.0483)
[2023/02/02 17:35] | ------------------------------------------------------------
[2023/02/02 17:35] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:35] | ------------------------------------------------------------
[2023/02/02 17:35] |    TRAIN(60)     0:01:14     0:00:49     0:00:24      0.0501
[2023/02/02 17:35] | ------------------------------------------------------------
[2023/02/02 17:35] | ****************************************************************************************************
[2023/02/02 17:35] | TRAIN(e061|iter5700): [27/93] Batch: 0.7749 (0.8028) Data: 0.5597 (0.5420) Loss: 0.0473 (0.0490)
[2023/02/02 17:36] | TRAIN(e061|iter5750): [77/93] Batch: 0.7924 (0.8005) Data: 0.5061 (0.5373) Loss: 0.0499 (0.0512)
[2023/02/02 17:36] | ------------------------------------------------------------
[2023/02/02 17:36] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:36] | ------------------------------------------------------------
[2023/02/02 17:36] |    TRAIN(61)     0:01:13     0:00:48     0:00:24      0.0511
[2023/02/02 17:36] | ------------------------------------------------------------
[2023/02/02 17:36] | ****************************************************************************************************
[2023/02/02 17:36] | TRAIN(e062|iter5800): [34/93] Batch: 0.8115 (0.8080) Data: 0.4920 (0.5443) Loss: 0.0373 (0.0427)
[2023/02/02 17:37] | TRAIN(e062|iter5850): [84/93] Batch: 0.7740 (0.8054) Data: 0.8010 (0.5450) Loss: 0.0709 (0.0483)
[2023/02/02 17:37] | ------------------------------------------------------------
[2023/02/02 17:37] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:37] | ------------------------------------------------------------
[2023/02/02 17:37] |    TRAIN(62)     0:01:14     0:00:49     0:00:24      0.0508
[2023/02/02 17:37] | ------------------------------------------------------------
[2023/02/02 17:37] | ****************************************************************************************************
[2023/02/02 17:38] | TRAIN(e063|iter5900): [41/93] Batch: 0.7770 (0.7963) Data: 0.6949 (0.5371) Loss: 0.0408 (0.0560)
[2023/02/02 17:38] | TRAIN(e063|iter5950): [91/93] Batch: 0.7175 (0.8064) Data: 0.5663 (0.5422) Loss: 0.0487 (0.0518)
[2023/02/02 17:38] | ------------------------------------------------------------
[2023/02/02 17:38] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:38] | ------------------------------------------------------------
[2023/02/02 17:38] |    TRAIN(63)     0:01:14     0:00:49     0:00:24      0.0523
[2023/02/02 17:38] | ------------------------------------------------------------
[2023/02/02 17:38] | ****************************************************************************************************
[2023/02/02 17:39] | TRAIN(e064|iter6000): [48/93] Batch: 0.7534 (0.7882) Data: 0.4412 (0.5233) Loss: 0.0384 (0.0527)
[2023/02/02 17:40] | ------------------------------------------------------------
[2023/02/02 17:40] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:40] | ------------------------------------------------------------
[2023/02/02 17:40] |    TRAIN(64)     0:01:13     0:00:48     0:00:24      0.0493
[2023/02/02 17:40] | ------------------------------------------------------------
[2023/02/02 17:40] | ****************************************************************************************************
[2023/02/02 17:40] | TRAIN(e065|iter6050): [ 5/93] Batch: 0.7570 (0.7493) Data: 0.5242 (0.4919) Loss: 0.0433 (0.0471)
[2023/02/02 17:40] | TRAIN(e065|iter6100): [55/93] Batch: 0.8326 (0.7808) Data: 0.4992 (0.5163) Loss: 0.0387 (0.0500)
[2023/02/02 17:41] | ------------------------------------------------------------
[2023/02/02 17:41] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:41] | ------------------------------------------------------------
[2023/02/02 17:41] |    TRAIN(65)     0:01:13     0:00:48     0:00:24      0.0504
[2023/02/02 17:41] | ------------------------------------------------------------
[2023/02/02 17:41] | ****************************************************************************************************
[2023/02/02 17:41] | TRAIN(e066|iter6150): [12/93] Batch: 1.0248 (0.8049) Data: 0.7502 (0.5578) Loss: 0.0409 (0.0510)
[2023/02/02 17:42] | TRAIN(e066|iter6200): [62/93] Batch: 0.7731 (0.8165) Data: 0.4871 (0.5513) Loss: 0.0455 (0.0570)
[2023/02/02 17:42] | ------------------------------------------------------------
[2023/02/02 17:42] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:42] | ------------------------------------------------------------
[2023/02/02 17:42] |    TRAIN(66)     0:01:14     0:00:50     0:00:24      0.0557
[2023/02/02 17:42] | ------------------------------------------------------------
[2023/02/02 17:42] | ****************************************************************************************************
[2023/02/02 17:42] | TRAIN(e067|iter6250): [19/93] Batch: 0.7379 (0.8251) Data: 0.5310 (0.5599) Loss: 0.0875 (0.0505)
[2023/02/02 17:43] | TRAIN(e067|iter6300): [69/93] Batch: 0.7546 (0.8196) Data: 0.5616 (0.5559) Loss: 0.0372 (0.0495)
[2023/02/02 17:43] | ------------------------------------------------------------
[2023/02/02 17:43] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:43] | ------------------------------------------------------------
[2023/02/02 17:43] |    TRAIN(67)     0:01:16     0:00:51     0:00:24      0.0480
[2023/02/02 17:43] | ------------------------------------------------------------
[2023/02/02 17:43] | ****************************************************************************************************
[2023/02/02 17:44] | TRAIN(e068|iter6350): [26/93] Batch: 0.7818 (0.7803) Data: 0.5020 (0.5152) Loss: 0.0906 (0.0514)
[2023/02/02 17:44] | TRAIN(e068|iter6400): [76/93] Batch: 0.7494 (0.7996) Data: 0.5558 (0.5355) Loss: 0.0422 (0.0485)
[2023/02/02 17:45] | ------------------------------------------------------------
[2023/02/02 17:45] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:45] | ------------------------------------------------------------
[2023/02/02 17:45] |    TRAIN(68)     0:01:13     0:00:49     0:00:24      0.0482
[2023/02/02 17:45] | ------------------------------------------------------------
[2023/02/02 17:45] | ****************************************************************************************************
[2023/02/02 17:45] | TRAIN(e069|iter6450): [33/93] Batch: 0.7198 (0.7900) Data: 0.4567 (0.5239) Loss: 0.0400 (0.0436)
[2023/02/02 17:46] | TRAIN(e069|iter6500): [83/93] Batch: 0.8754 (0.8113) Data: 0.7038 (0.5492) Loss: 0.0366 (0.0445)
[2023/02/02 17:46] | ------------------------------------------------------------
[2023/02/02 17:46] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 17:46] | ------------------------------------------------------------
[2023/02/02 17:46] |    TRAIN(69)     0:01:16     0:00:51     0:00:24      0.0452
[2023/02/02 17:46] | ------------------------------------------------------------
[2023/02/02 17:46] | ====================================================================================================
[2023/02/02 17:48] | idx 0 case case0008 mean_dice 0.597157 mean_hd95 26.162832
[2023/02/02 17:49] | idx 1 case case0022 mean_dice 0.866790 mean_hd95 23.427412
[2023/02/02 17:50] | idx 2 case case0038 mean_dice 0.714294 mean_hd95 41.681243
[2023/02/02 17:53] | idx 3 case case0036 mean_dice 0.787368 mean_hd95 39.935509
[2023/02/02 17:54] | idx 4 case case0032 mean_dice 0.762771 mean_hd95 21.539711
[2023/02/02 17:56] | idx 5 case case0002 mean_dice 0.856490 mean_hd95 7.446939
[2023/02/02 17:57] | idx 6 case case0029 mean_dice 0.690276 mean_hd95 23.386635
[2023/02/02 18:00] | idx 7 case case0003 mean_dice 0.645552 mean_hd95 88.792824
[2023/02/02 18:02] | idx 8 case case0001 mean_dice 0.750465 mean_hd95 39.828941
[2023/02/02 18:04] | idx 9 case case0004 mean_dice 0.758180 mean_hd95 8.506712
[2023/02/02 18:05] | idx 10 case case0025 mean_dice 0.785884 mean_hd95 41.178636
[2023/02/02 18:06] | idx 11 case case0035 mean_dice 0.845424 mean_hd95 8.011893
[2023/02/02 18:06] | Mean class 1 mean_dice 0.848202 mean_hd95 8.748941
[2023/02/02 18:06] | Mean class 2 mean_dice 0.617552 mean_hd95 39.560637
[2023/02/02 18:06] | Mean class 3 mean_dice 0.798250 mean_hd95 76.822274
[2023/02/02 18:06] | Mean class 4 mean_dice 0.680977 mean_hd95 15.520219
[2023/02/02 18:06] | Mean class 5 mean_dice 0.939803 mean_hd95 25.018428
[2023/02/02 18:06] | Mean class 6 mean_dice 0.596595 mean_hd95 17.865708
[2023/02/02 18:06] | Mean class 7 mean_dice 0.824839 mean_hd95 43.161982
[2023/02/02 18:06] | Mean class 8 mean_dice 0.734218 mean_hd95 19.901336
[2023/02/02 18:06] | Testing performance>>  mean_dice : 0.755054  mean_hd95 : 30.824941
[2023/02/02 18:06] | ====================================================================================================
[2023/02/02 18:06] | >>>>> best model is changed <<<<<
[2023/02/02 18:06] | ****************************************************************************************************
[2023/02/02 18:07] | TRAIN(e070|iter6550): [40/93] Batch: 1.1227 (1.0324) Data: 0.5971 (0.7612) Loss: 0.0393 (0.0501)
[2023/02/02 18:08] | TRAIN(e070|iter6600): [90/93] Batch: 1.0702 (1.0241) Data: 0.9517 (0.7595) Loss: 0.0427 (0.0502)
[2023/02/02 18:08] | ------------------------------------------------------------
[2023/02/02 18:08] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:08] | ------------------------------------------------------------
[2023/02/02 18:08] |    TRAIN(70)     0:01:34     0:01:10     0:00:24      0.0506
[2023/02/02 18:08] | ------------------------------------------------------------
[2023/02/02 18:08] | ****************************************************************************************************
[2023/02/02 18:09] | TRAIN(e071|iter6650): [47/93] Batch: 0.9293 (1.0152) Data: 0.4948 (0.7423) Loss: 0.0386 (0.0415)
[2023/02/02 18:09] | ------------------------------------------------------------
[2023/02/02 18:09] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:09] | ------------------------------------------------------------
[2023/02/02 18:09] |    TRAIN(71)     0:01:33     0:01:08     0:00:24      0.0455
[2023/02/02 18:09] | ------------------------------------------------------------
[2023/02/02 18:09] | ****************************************************************************************************
[2023/02/02 18:10] | TRAIN(e072|iter6700): [ 4/93] Batch: 0.7509 (0.9157) Data: 0.8332 (0.6863) Loss: 0.0442 (0.0383)
[2023/02/02 18:10] | TRAIN(e072|iter6750): [54/93] Batch: 0.9228 (1.0437) Data: 0.8870 (0.7763) Loss: 0.0403 (0.0425)
[2023/02/02 18:11] | ------------------------------------------------------------
[2023/02/02 18:11] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:11] | ------------------------------------------------------------
[2023/02/02 18:11] |    TRAIN(72)     0:01:40     0:01:15     0:00:25      0.0431
[2023/02/02 18:11] | ------------------------------------------------------------
[2023/02/02 18:11] | ****************************************************************************************************
[2023/02/02 18:11] | TRAIN(e073|iter6800): [11/93] Batch: 1.0875 (1.1106) Data: 0.7347 (0.8282) Loss: 0.0454 (0.0513)
[2023/02/02 18:12] | TRAIN(e073|iter6850): [61/93] Batch: 1.0693 (1.0938) Data: 0.8089 (0.8210) Loss: 0.0393 (0.0474)
[2023/02/02 18:13] | ------------------------------------------------------------
[2023/02/02 18:13] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:13] | ------------------------------------------------------------
[2023/02/02 18:13] |    TRAIN(73)     0:01:38     0:01:13     0:00:25      0.0463
[2023/02/02 18:13] | ------------------------------------------------------------
[2023/02/02 18:13] | ****************************************************************************************************
[2023/02/02 18:13] | TRAIN(e074|iter6900): [18/93] Batch: 1.0158 (1.0017) Data: 0.8648 (0.7407) Loss: 0.0493 (0.0450)
[2023/02/02 18:14] | TRAIN(e074|iter6950): [68/93] Batch: 1.2415 (1.0465) Data: 0.7085 (0.7750) Loss: 0.0403 (0.0408)
[2023/02/02 18:14] | ------------------------------------------------------------
[2023/02/02 18:14] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:14] | ------------------------------------------------------------
[2023/02/02 18:14] |    TRAIN(74)     0:01:35     0:01:10     0:00:25      0.0411
[2023/02/02 18:14] | ------------------------------------------------------------
[2023/02/02 18:14] | ****************************************************************************************************
[2023/02/02 18:15] | TRAIN(e075|iter7000): [25/93] Batch: 0.8902 (1.0019) Data: 0.8284 (0.7356) Loss: 0.0318 (0.0372)
[2023/02/02 18:16] | TRAIN(e075|iter7050): [75/93] Batch: 0.7821 (1.0155) Data: 0.9061 (0.7451) Loss: 0.0308 (0.0419)
[2023/02/02 18:16] | ------------------------------------------------------------
[2023/02/02 18:16] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:16] | ------------------------------------------------------------
[2023/02/02 18:16] |    TRAIN(75)     0:01:33     0:01:08     0:00:25      0.0423
[2023/02/02 18:16] | ------------------------------------------------------------
[2023/02/02 18:16] | ****************************************************************************************************
[2023/02/02 18:17] | TRAIN(e076|iter7100): [32/93] Batch: 1.1975 (1.0403) Data: 0.8892 (0.7727) Loss: 0.0316 (0.0456)
[2023/02/02 18:17] | TRAIN(e076|iter7150): [82/93] Batch: 1.0789 (1.0838) Data: 0.7640 (0.8110) Loss: 0.0832 (0.0476)
[2023/02/02 18:18] | ------------------------------------------------------------
[2023/02/02 18:18] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:18] | ------------------------------------------------------------
[2023/02/02 18:18] |    TRAIN(76)     0:01:40     0:01:15     0:00:25      0.0464
[2023/02/02 18:18] | ------------------------------------------------------------
[2023/02/02 18:18] | ****************************************************************************************************
[2023/02/02 18:18] | TRAIN(e077|iter7200): [39/93] Batch: 0.8139 (1.0509) Data: 0.5297 (0.7752) Loss: 0.0358 (0.0417)
[2023/02/02 18:19] | TRAIN(e077|iter7250): [89/93] Batch: 1.1294 (1.0337) Data: 0.5410 (0.7606) Loss: 0.1014 (0.0415)
[2023/02/02 18:19] | ------------------------------------------------------------
[2023/02/02 18:19] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:19] | ------------------------------------------------------------
[2023/02/02 18:19] |    TRAIN(77)     0:01:35     0:01:10     0:00:25      0.0416
[2023/02/02 18:19] | ------------------------------------------------------------
[2023/02/02 18:19] | ****************************************************************************************************
[2023/02/02 18:20] | TRAIN(e078|iter7300): [46/93] Batch: 0.9838 (0.9943) Data: 0.8665 (0.7270) Loss: 0.1351 (0.0532)
[2023/02/02 18:21] | ------------------------------------------------------------
[2023/02/02 18:21] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:21] | ------------------------------------------------------------
[2023/02/02 18:21] |    TRAIN(78)     0:01:30     0:01:05     0:00:24      0.0500
[2023/02/02 18:21] | ------------------------------------------------------------
[2023/02/02 18:21] | ****************************************************************************************************
[2023/02/02 18:21] | TRAIN(e079|iter7350): [ 3/93] Batch: 1.1184 (1.0622) Data: 0.7122 (0.7712) Loss: 0.0361 (0.0830)
[2023/02/02 18:22] | TRAIN(e079|iter7400): [53/93] Batch: 1.1032 (1.0185) Data: 0.6979 (0.7477) Loss: 0.0424 (0.0527)
[2023/02/02 18:22] | ------------------------------------------------------------
[2023/02/02 18:22] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:22] | ------------------------------------------------------------
[2023/02/02 18:22] |    TRAIN(79)     0:01:34     0:01:09     0:00:25      0.0514
[2023/02/02 18:22] | ------------------------------------------------------------
[2023/02/02 18:22] | ====================================================================================================
[2023/02/02 18:24] | idx 0 case case0008 mean_dice 0.600071 mean_hd95 25.302316
[2023/02/02 18:26] | idx 1 case case0022 mean_dice 0.887850 mean_hd95 6.777823
[2023/02/02 18:27] | idx 2 case case0038 mean_dice 0.769497 mean_hd95 36.865424
[2023/02/02 18:30] | idx 3 case case0036 mean_dice 0.820362 mean_hd95 46.209842
[2023/02/02 18:32] | idx 4 case case0032 mean_dice 0.743854 mean_hd95 22.384745
[2023/02/02 18:33] | idx 5 case case0002 mean_dice 0.865219 mean_hd95 12.984546
[2023/02/02 18:35] | idx 6 case case0029 mean_dice 0.746536 mean_hd95 28.394281
[2023/02/02 18:38] | idx 7 case case0003 mean_dice 0.676844 mean_hd95 108.580678
[2023/02/02 18:40] | idx 8 case case0001 mean_dice 0.742528 mean_hd95 55.671992
[2023/02/02 18:42] | idx 9 case case0004 mean_dice 0.779981 mean_hd95 7.809816
[2023/02/02 18:43] | idx 10 case case0025 mean_dice 0.813962 mean_hd95 38.165401
[2023/02/02 18:44] | idx 11 case case0035 mean_dice 0.851228 mean_hd95 7.805605
[2023/02/02 18:44] | Mean class 1 mean_dice 0.865750 mean_hd95 11.314915
[2023/02/02 18:44] | Mean class 2 mean_dice 0.628723 mean_hd95 39.852342
[2023/02/02 18:44] | Mean class 3 mean_dice 0.792168 mean_hd95 71.199553
[2023/02/02 18:44] | Mean class 4 mean_dice 0.785636 mean_hd95 31.316109
[2023/02/02 18:44] | Mean class 5 mean_dice 0.943059 mean_hd95 23.090436
[2023/02/02 18:44] | Mean class 6 mean_dice 0.608174 mean_hd95 12.593965
[2023/02/02 18:44] | Mean class 7 mean_dice 0.849735 mean_hd95 56.627619
[2023/02/02 18:44] | Mean class 8 mean_dice 0.725377 mean_hd95 18.640038
[2023/02/02 18:44] | Testing performance>>  mean_dice : 0.774828  mean_hd95 : 33.079372
[2023/02/02 18:44] | ====================================================================================================
[2023/02/02 18:44] | >>>>> best model is changed <<<<<
[2023/02/02 18:44] | ****************************************************************************************************
[2023/02/02 18:44] | TRAIN(e080|iter7450): [10/93] Batch: 0.7738 (0.9705) Data: 0.5382 (0.6926) Loss: 0.0887 (0.0439)
[2023/02/02 18:45] | TRAIN(e080|iter7500): [60/93] Batch: 1.0781 (1.0544) Data: 0.8226 (0.7876) Loss: 0.0288 (0.0418)
[2023/02/02 18:45] | ------------------------------------------------------------
[2023/02/02 18:45] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:45] | ------------------------------------------------------------
[2023/02/02 18:45] |    TRAIN(80)     0:01:37     0:01:13     0:00:24      0.0424
[2023/02/02 18:45] | ------------------------------------------------------------
[2023/02/02 18:45] | ****************************************************************************************************
[2023/02/02 18:46] | TRAIN(e081|iter7550): [17/93] Batch: 0.8167 (0.9547) Data: 0.6046 (0.6828) Loss: 0.0493 (0.0442)
[2023/02/02 18:47] | TRAIN(e081|iter7600): [67/93] Batch: 1.0114 (0.9750) Data: 0.9296 (0.7111) Loss: 0.0416 (0.0465)
[2023/02/02 18:47] | ------------------------------------------------------------
[2023/02/02 18:47] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:47] | ------------------------------------------------------------
[2023/02/02 18:47] |    TRAIN(81)     0:01:31     0:01:06     0:00:24      0.0456
[2023/02/02 18:47] | ------------------------------------------------------------
[2023/02/02 18:47] | ****************************************************************************************************
[2023/02/02 18:47] | TRAIN(e082|iter7650): [24/93] Batch: 1.1428 (1.0229) Data: 0.6218 (0.7473) Loss: 0.0385 (0.0426)
[2023/02/02 18:48] | TRAIN(e082|iter7700): [74/93] Batch: 0.9447 (1.0131) Data: 0.8534 (0.7442) Loss: 0.0861 (0.0457)
[2023/02/02 18:48] | ------------------------------------------------------------
[2023/02/02 18:48] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:48] | ------------------------------------------------------------
[2023/02/02 18:48] |    TRAIN(82)     0:01:33     0:01:08     0:00:25      0.0461
[2023/02/02 18:48] | ------------------------------------------------------------
[2023/02/02 18:48] | ****************************************************************************************************
[2023/02/02 18:49] | TRAIN(e083|iter7750): [31/93] Batch: 1.0386 (1.0264) Data: 0.6287 (0.7529) Loss: 0.0534 (0.0482)
[2023/02/02 18:50] | TRAIN(e083|iter7800): [81/93] Batch: 0.9394 (1.0236) Data: 0.8800 (0.7555) Loss: 0.0524 (0.0450)
[2023/02/02 18:50] | ------------------------------------------------------------
[2023/02/02 18:50] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:50] | ------------------------------------------------------------
[2023/02/02 18:50] |    TRAIN(83)     0:01:34     0:01:09     0:00:24      0.0441
[2023/02/02 18:50] | ------------------------------------------------------------
[2023/02/02 18:50] | ****************************************************************************************************
[2023/02/02 18:51] | TRAIN(e084|iter7850): [38/93] Batch: 1.1795 (1.0983) Data: 0.8879 (0.8284) Loss: 0.0342 (0.0407)
[2023/02/02 18:52] | TRAIN(e084|iter7900): [88/93] Batch: 1.0371 (1.0990) Data: 0.8599 (0.8276) Loss: 0.0452 (0.0412)
[2023/02/02 18:52] | ------------------------------------------------------------
[2023/02/02 18:52] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:52] | ------------------------------------------------------------
[2023/02/02 18:52] |    TRAIN(84)     0:01:40     0:01:15     0:00:25      0.0420
[2023/02/02 18:52] | ------------------------------------------------------------
[2023/02/02 18:52] | ****************************************************************************************************
[2023/02/02 18:53] | TRAIN(e085|iter7950): [45/93] Batch: 1.2792 (1.0287) Data: 0.6847 (0.7573) Loss: 0.0375 (0.0403)
[2023/02/02 18:53] | ------------------------------------------------------------
[2023/02/02 18:53] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:53] | ------------------------------------------------------------
[2023/02/02 18:53] |    TRAIN(85)     0:01:35     0:01:10     0:00:25      0.0402
[2023/02/02 18:53] | ------------------------------------------------------------
[2023/02/02 18:53] | ****************************************************************************************************
[2023/02/02 18:53] | TRAIN(e086|iter8000): [ 2/93] Batch: 0.9898 (1.0040) Data: 0.9842 (0.8194) Loss: 0.0358 (0.0513)
[2023/02/02 18:54] | TRAIN(e086|iter8050): [52/93] Batch: 0.9116 (1.0106) Data: 0.5738 (0.7371) Loss: 0.0392 (0.0427)
[2023/02/02 18:55] | ------------------------------------------------------------
[2023/02/02 18:55] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:55] | ------------------------------------------------------------
[2023/02/02 18:55] |    TRAIN(86)     0:01:33     0:01:08     0:00:25      0.0405
[2023/02/02 18:55] | ------------------------------------------------------------
[2023/02/02 18:55] | ****************************************************************************************************
[2023/02/02 18:55] | TRAIN(e087|iter8100): [ 9/93] Batch: 0.7735 (0.9935) Data: 0.8575 (0.7384) Loss: 0.0269 (0.0384)
[2023/02/02 18:56] | TRAIN(e087|iter8150): [59/93] Batch: 1.0165 (0.9912) Data: 0.5159 (0.7190) Loss: 0.0348 (0.0395)
[2023/02/02 18:56] | ------------------------------------------------------------
[2023/02/02 18:56] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:56] | ------------------------------------------------------------
[2023/02/02 18:56] |    TRAIN(87)     0:01:31     0:01:06     0:00:24      0.0395
[2023/02/02 18:56] | ------------------------------------------------------------
[2023/02/02 18:56] | ****************************************************************************************************
[2023/02/02 18:57] | TRAIN(e088|iter8200): [16/93] Batch: 1.0994 (1.1082) Data: 0.9228 (0.8403) Loss: 0.0332 (0.0375)
[2023/02/02 18:58] | TRAIN(e088|iter8250): [66/93] Batch: 0.7509 (1.0964) Data: 0.6327 (0.8205) Loss: 0.0396 (0.0398)
[2023/02/02 18:58] | ------------------------------------------------------------
[2023/02/02 18:58] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 18:58] | ------------------------------------------------------------
[2023/02/02 18:58] |    TRAIN(88)     0:01:39     0:01:13     0:00:25      0.0393
[2023/02/02 18:58] | ------------------------------------------------------------
[2023/02/02 18:58] | ****************************************************************************************************
[2023/02/02 18:58] | TRAIN(e089|iter8300): [23/93] Batch: 0.8672 (1.0371) Data: 0.7362 (0.7630) Loss: 0.0352 (0.0372)
[2023/02/02 18:59] | TRAIN(e089|iter8350): [73/93] Batch: 0.9464 (1.0266) Data: 0.8241 (0.7568) Loss: 0.0340 (0.0391)
[2023/02/02 19:00] | ------------------------------------------------------------
[2023/02/02 19:00] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 19:00] | ------------------------------------------------------------
[2023/02/02 19:00] |    TRAIN(89)     0:01:35     0:01:09     0:00:25      0.0382
[2023/02/02 19:00] | ------------------------------------------------------------
[2023/02/02 19:00] | ====================================================================================================
[2023/02/02 19:02] | idx 0 case case0008 mean_dice 0.606106 mean_hd95 32.150118
[2023/02/02 19:03] | idx 1 case case0022 mean_dice 0.887986 mean_hd95 3.260014
[2023/02/02 19:04] | idx 2 case case0038 mean_dice 0.785241 mean_hd95 39.269091
[2023/02/02 19:07] | idx 3 case case0036 mean_dice 0.806444 mean_hd95 28.392055
[2023/02/02 19:09] | idx 4 case case0032 mean_dice 0.795055 mean_hd95 19.558252
[2023/02/02 19:11] | idx 5 case case0002 mean_dice 0.873079 mean_hd95 5.185685
[2023/02/02 19:12] | idx 6 case case0029 mean_dice 0.748315 mean_hd95 43.779840
[2023/02/02 19:15] | idx 7 case case0003 mean_dice 0.719466 mean_hd95 90.490031
[2023/02/02 19:17] | idx 8 case case0001 mean_dice 0.748224 mean_hd95 44.784841
[2023/02/02 19:19] | idx 9 case case0004 mean_dice 0.781115 mean_hd95 7.583391
[2023/02/02 19:20] | idx 10 case case0025 mean_dice 0.826387 mean_hd95 38.781383
[2023/02/02 19:21] | idx 11 case case0035 mean_dice 0.864800 mean_hd95 7.639980
[2023/02/02 19:21] | Mean class 1 mean_dice 0.874326 mean_hd95 15.008265
[2023/02/02 19:21] | Mean class 2 mean_dice 0.647896 mean_hd95 19.206369
[2023/02/02 19:21] | Mean class 3 mean_dice 0.819547 mean_hd95 67.658803
[2023/02/02 19:21] | Mean class 4 mean_dice 0.791083 mean_hd95 34.281133
[2023/02/02 19:21] | Mean class 5 mean_dice 0.941567 mean_hd95 23.896694
[2023/02/02 19:21] | Mean class 6 mean_dice 0.605022 mean_hd95 14.598192
[2023/02/02 19:21] | Mean class 7 mean_dice 0.855975 mean_hd95 44.990821
[2023/02/02 19:21] | Mean class 8 mean_dice 0.759396 mean_hd95 20.942843
[2023/02/02 19:21] | Testing performance>>  mean_dice : 0.786852  mean_hd95 : 30.072890
[2023/02/02 19:21] | ====================================================================================================
[2023/02/02 19:21] | >>>>> best model is changed <<<<<
[2023/02/02 19:21] | ****************************************************************************************************
[2023/02/02 19:22] | TRAIN(e090|iter8400): [30/93] Batch: 1.2600 (1.0196) Data: 0.6536 (0.7500) Loss: 0.0351 (0.0378)
[2023/02/02 19:23] | TRAIN(e090|iter8450): [80/93] Batch: 1.2399 (1.0178) Data: 0.7939 (0.7521) Loss: 0.0389 (0.0397)
[2023/02/02 19:23] | ------------------------------------------------------------
[2023/02/02 19:23] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 19:23] | ------------------------------------------------------------
[2023/02/02 19:23] |    TRAIN(90)     0:01:33     0:01:09     0:00:24      0.0393
[2023/02/02 19:23] | ------------------------------------------------------------
[2023/02/02 19:23] | ****************************************************************************************************
[2023/02/02 19:23] | TRAIN(e091|iter8500): [37/93] Batch: 1.1997 (1.0531) Data: 0.6792 (0.7809) Loss: 0.0255 (0.0358)
[2023/02/02 19:24] | TRAIN(e091|iter8550): [87/93] Batch: 1.1639 (1.0357) Data: 0.5608 (0.7640) Loss: 0.0358 (0.0363)
[2023/02/02 19:24] | ------------------------------------------------------------
[2023/02/02 19:24] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 19:24] | ------------------------------------------------------------
[2023/02/02 19:24] |    TRAIN(91)     0:01:35     0:01:10     0:00:24      0.0365
[2023/02/02 19:24] | ------------------------------------------------------------
[2023/02/02 19:24] | ****************************************************************************************************
[2023/02/02 19:25] | TRAIN(e092|iter8600): [44/93] Batch: 1.0639 (1.1882) Data: 0.8145 (0.9118) Loss: 0.0327 (0.0374)
[2023/02/02 19:26] | ------------------------------------------------------------
[2023/02/02 19:26] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 19:26] | ------------------------------------------------------------
[2023/02/02 19:26] |    TRAIN(92)     0:01:46     0:01:21     0:00:25      0.0371
[2023/02/02 19:26] | ------------------------------------------------------------
[2023/02/02 19:26] | ****************************************************************************************************
[2023/02/02 19:26] | TRAIN(e093|iter8650): [ 1/93] Batch: 1.1548 (1.1548) Data: 0.5648 (0.7236) Loss: 0.0330 (0.0326)
[2023/02/02 19:27] | TRAIN(e093|iter8700): [51/93] Batch: 0.8243 (1.0506) Data: 0.7593 (0.7796) Loss: 0.0339 (0.0383)
[2023/02/02 19:28] | ------------------------------------------------------------
[2023/02/02 19:28] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 19:28] | ------------------------------------------------------------
[2023/02/02 19:28] |    TRAIN(93)     0:01:38     0:01:13     0:00:25      0.0398
[2023/02/02 19:28] | ------------------------------------------------------------
[2023/02/02 19:28] | ****************************************************************************************************
[2023/02/02 19:28] | TRAIN(e094|iter8750): [ 8/93] Batch: 0.9257 (1.0042) Data: 0.7538 (0.7349) Loss: 0.0323 (0.0434)
[2023/02/02 19:29] | TRAIN(e094|iter8800): [58/93] Batch: 1.1761 (1.0632) Data: 0.7206 (0.7908) Loss: 0.0593 (0.0424)
[2023/02/02 19:29] | ------------------------------------------------------------
[2023/02/02 19:29] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 19:29] | ------------------------------------------------------------
[2023/02/02 19:29] |    TRAIN(94)     0:01:37     0:01:12     0:00:25      0.0418
[2023/02/02 19:29] | ------------------------------------------------------------
[2023/02/02 19:29] | ****************************************************************************************************
[2023/02/02 19:30] | TRAIN(e095|iter8850): [15/93] Batch: 1.2868 (1.0699) Data: 0.4956 (0.7792) Loss: 0.0863 (0.0495)
[2023/02/02 19:31] | TRAIN(e095|iter8900): [65/93] Batch: 0.8528 (1.0470) Data: 0.5274 (0.7726) Loss: 0.0354 (0.0450)
[2023/02/02 19:31] | ------------------------------------------------------------
[2023/02/02 19:31] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 19:31] | ------------------------------------------------------------
[2023/02/02 19:31] |    TRAIN(95)     0:01:36     0:01:11     0:00:25      0.0439
[2023/02/02 19:31] | ------------------------------------------------------------
[2023/02/02 19:31] | ****************************************************************************************************
[2023/02/02 19:31] | TRAIN(e096|iter8950): [22/93] Batch: 1.0779 (1.1874) Data: 0.8407 (0.9082) Loss: 0.0398 (0.0475)
[2023/02/02 19:32] | TRAIN(e096|iter9000): [72/93] Batch: 1.0707 (1.1610) Data: 1.0197 (0.8888) Loss: 0.0306 (0.0409)
[2023/02/02 19:33] | ------------------------------------------------------------
[2023/02/02 19:33] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 19:33] | ------------------------------------------------------------
[2023/02/02 19:33] |    TRAIN(96)     0:01:45     0:01:19     0:00:25      0.0408
[2023/02/02 19:33] | ------------------------------------------------------------
[2023/02/02 19:33] | ****************************************************************************************************
[2023/02/02 19:33] | TRAIN(e097|iter9050): [29/93] Batch: 1.1065 (1.0356) Data: 0.8799 (0.7685) Loss: 0.0357 (0.0363)
[2023/02/02 19:34] | TRAIN(e097|iter9100): [79/93] Batch: 0.9435 (1.0212) Data: 0.7224 (0.7507) Loss: 0.0363 (0.0381)
[2023/02/02 19:34] | ------------------------------------------------------------
[2023/02/02 19:34] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 19:34] | ------------------------------------------------------------
[2023/02/02 19:34] |    TRAIN(97)     0:01:34     0:01:09     0:00:25      0.0377
[2023/02/02 19:34] | ------------------------------------------------------------
[2023/02/02 19:34] | ****************************************************************************************************
[2023/02/02 19:35] | TRAIN(e098|iter9150): [36/93] Batch: 0.7884 (0.9959) Data: 0.8520 (0.7299) Loss: 0.0379 (0.0427)
[2023/02/02 19:36] | TRAIN(e098|iter9200): [86/93] Batch: 1.0749 (1.0188) Data: 0.5629 (0.7460) Loss: 0.0393 (0.0409)
[2023/02/02 19:36] | ------------------------------------------------------------
[2023/02/02 19:36] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 19:36] | ------------------------------------------------------------
[2023/02/02 19:36] |    TRAIN(98)     0:01:33     0:01:08     0:00:25      0.0404
[2023/02/02 19:36] | ------------------------------------------------------------
[2023/02/02 19:36] | ****************************************************************************************************
[2023/02/02 19:37] | TRAIN(e099|iter9250): [43/93] Batch: 1.0942 (0.9847) Data: 0.5960 (0.7123) Loss: 0.0479 (0.0448)
[2023/02/02 19:37] | ------------------------------------------------------------
[2023/02/02 19:37] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 19:37] | ------------------------------------------------------------
[2023/02/02 19:37] |    TRAIN(99)     0:01:35     0:01:09     0:00:25      0.0427
[2023/02/02 19:37] | ------------------------------------------------------------
[2023/02/02 19:37] | ====================================================================================================
[2023/02/02 19:40] | idx 0 case case0008 mean_dice 0.605455 mean_hd95 25.059397
[2023/02/02 19:41] | idx 1 case case0022 mean_dice 0.869715 mean_hd95 10.378178
[2023/02/02 19:42] | idx 2 case case0038 mean_dice 0.748170 mean_hd95 86.407291
[2023/02/02 19:45] | idx 3 case case0036 mean_dice 0.798914 mean_hd95 26.927215
[2023/02/02 19:47] | idx 4 case case0032 mean_dice 0.761541 mean_hd95 21.224243
[2023/02/02 19:49] | idx 5 case case0002 mean_dice 0.869350 mean_hd95 23.133011
[2023/02/02 19:50] | idx 6 case case0029 mean_dice 0.763832 mean_hd95 41.479508
[2023/02/02 19:53] | idx 7 case case0003 mean_dice 0.680441 mean_hd95 97.737274
[2023/02/02 19:55] | idx 8 case case0001 mean_dice 0.764063 mean_hd95 47.940095
[2023/02/02 19:57] | idx 9 case case0004 mean_dice 0.786955 mean_hd95 16.872653
[2023/02/02 19:58] | idx 10 case case0025 mean_dice 0.821494 mean_hd95 44.420494
[2023/02/02 19:59] | idx 11 case case0035 mean_dice 0.852654 mean_hd95 32.140522
[2023/02/02 19:59] | Mean class 1 mean_dice 0.875017 mean_hd95 21.921531
[2023/02/02 19:59] | Mean class 2 mean_dice 0.637044 mean_hd95 54.779883
[2023/02/02 19:59] | Mean class 3 mean_dice 0.817156 mean_hd95 68.424989
[2023/02/02 19:59] | Mean class 4 mean_dice 0.802319 mean_hd95 67.264549
[2023/02/02 19:59] | Mean class 5 mean_dice 0.937877 mean_hd95 25.965646
[2023/02/02 19:59] | Mean class 6 mean_dice 0.589718 mean_hd95 11.855903
[2023/02/02 19:59] | Mean class 7 mean_dice 0.825594 mean_hd95 46.850267
[2023/02/02 19:59] | Mean class 8 mean_dice 0.730330 mean_hd95 18.750486
[2023/02/02 19:59] | Testing performance>>  mean_dice : 0.776882  mean_hd95 : 39.476657
[2023/02/02 19:59] | ====================================================================================================
[2023/02/02 19:59] | ****************************************************************************************************
[2023/02/02 19:59] | TRAIN(e100|iter9300): [ 0/93] Batch: 0.0000 (0.0000) Data: 0.6616 (0.6616) Loss: 0.0319 (0.0319)
[2023/02/02 20:00] | TRAIN(e100|iter9350): [50/93] Batch: 1.0670 (1.0012) Data: 0.8039 (0.7369) Loss: 0.0254 (0.0377)
[2023/02/02 20:01] | ------------------------------------------------------------
[2023/02/02 20:01] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:01] | ------------------------------------------------------------
[2023/02/02 20:01] |   TRAIN(100)     0:01:31     0:01:07     0:00:24      0.0391
[2023/02/02 20:01] | ------------------------------------------------------------
[2023/02/02 20:01] | ****************************************************************************************************
[2023/02/02 20:01] | TRAIN(e101|iter9400): [ 7/93] Batch: 1.1023 (1.0391) Data: 0.7371 (0.7661) Loss: 0.0244 (0.0361)
[2023/02/02 20:02] | TRAIN(e101|iter9450): [57/93] Batch: 1.0828 (1.0518) Data: 0.8872 (0.7849) Loss: 0.0282 (0.0375)
[2023/02/02 20:02] | ------------------------------------------------------------
[2023/02/02 20:02] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:02] | ------------------------------------------------------------
[2023/02/02 20:02] |   TRAIN(101)     0:01:39     0:01:14     0:00:25      0.0386
[2023/02/02 20:02] | ------------------------------------------------------------
[2023/02/02 20:02] | ****************************************************************************************************
[2023/02/02 20:03] | TRAIN(e102|iter9500): [14/93] Batch: 1.1825 (1.0932) Data: 0.9989 (0.8339) Loss: 0.0357 (0.0446)
[2023/02/02 20:03] | TRAIN(e102|iter9550): [64/93] Batch: 1.3243 (1.1263) Data: 0.9961 (0.8569) Loss: 0.0243 (0.0378)
[2023/02/02 20:04] | ------------------------------------------------------------
[2023/02/02 20:04] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:04] | ------------------------------------------------------------
[2023/02/02 20:04] |   TRAIN(102)     0:01:43     0:01:18     0:00:25      0.0374
[2023/02/02 20:04] | ------------------------------------------------------------
[2023/02/02 20:04] | ****************************************************************************************************
[2023/02/02 20:04] | TRAIN(e103|iter9600): [21/93] Batch: 0.8753 (1.1170) Data: 1.0454 (0.8528) Loss: 0.0262 (0.0334)
[2023/02/02 20:05] | TRAIN(e103|iter9650): [71/93] Batch: 1.2055 (1.1407) Data: 0.8843 (0.8663) Loss: 0.0294 (0.0348)
[2023/02/02 20:06] | ------------------------------------------------------------
[2023/02/02 20:06] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:06] | ------------------------------------------------------------
[2023/02/02 20:06] |   TRAIN(103)     0:01:44     0:01:19     0:00:25      0.0360
[2023/02/02 20:06] | ------------------------------------------------------------
[2023/02/02 20:06] | ****************************************************************************************************
[2023/02/02 20:06] | TRAIN(e104|iter9700): [28/93] Batch: 0.8307 (1.1274) Data: 0.4993 (0.8417) Loss: 0.0374 (0.0404)
[2023/02/02 20:07] | TRAIN(e104|iter9750): [78/93] Batch: 1.1432 (1.1248) Data: 0.9851 (0.8529) Loss: 0.0278 (0.0377)
[2023/02/02 20:07] | ------------------------------------------------------------
[2023/02/02 20:07] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:07] | ------------------------------------------------------------
[2023/02/02 20:07] |   TRAIN(104)     0:01:43     0:01:18     0:00:25      0.0377
[2023/02/02 20:07] | ------------------------------------------------------------
[2023/02/02 20:07] | ****************************************************************************************************
[2023/02/02 20:08] | TRAIN(e105|iter9800): [35/93] Batch: 1.1794 (1.1229) Data: 1.0605 (0.8578) Loss: 0.0331 (0.0354)
[2023/02/02 20:09] | TRAIN(e105|iter9850): [85/93] Batch: 1.1423 (1.1955) Data: 0.9113 (0.9214) Loss: 0.0363 (0.0383)
[2023/02/02 20:09] | ------------------------------------------------------------
[2023/02/02 20:09] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:09] | ------------------------------------------------------------
[2023/02/02 20:09] |   TRAIN(105)     0:01:50     0:01:24     0:00:25      0.0381
[2023/02/02 20:09] | ------------------------------------------------------------
[2023/02/02 20:09] | ****************************************************************************************************
[2023/02/02 20:10] | TRAIN(e106|iter9900): [42/93] Batch: 0.7630 (1.1709) Data: 0.8694 (0.8959) Loss: 0.0841 (0.0362)
[2023/02/02 20:11] | TRAIN(e106|iter9950): [92/93] Batch: 1.0846 (1.1435) Data: 0.1483 (0.8623) Loss: 0.1462 (0.0370)
[2023/02/02 20:11] | ------------------------------------------------------------
[2023/02/02 20:11] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:11] | ------------------------------------------------------------
[2023/02/02 20:11] |   TRAIN(106)     0:01:45     0:01:20     0:00:25      0.0370
[2023/02/02 20:11] | ------------------------------------------------------------
[2023/02/02 20:11] | ****************************************************************************************************
[2023/02/02 20:12] | TRAIN(e107|iter10000): [49/93] Batch: 1.1757 (1.1310) Data: 0.9991 (0.8607) Loss: 0.0319 (0.0360)
[2023/02/02 20:13] | ------------------------------------------------------------
[2023/02/02 20:13] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:13] | ------------------------------------------------------------
[2023/02/02 20:13] |   TRAIN(107)     0:01:44     0:01:18     0:00:25      0.0364
[2023/02/02 20:13] | ------------------------------------------------------------
[2023/02/02 20:13] | ****************************************************************************************************
[2023/02/02 20:13] | TRAIN(e108|iter10050): [ 6/93] Batch: 1.0968 (1.0743) Data: 0.9921 (0.8297) Loss: 0.0390 (0.0472)
[2023/02/02 20:14] | TRAIN(e108|iter10100): [56/93] Batch: 1.1983 (1.0987) Data: 0.7880 (0.8258) Loss: 0.0427 (0.0384)
[2023/02/02 20:14] | ------------------------------------------------------------
[2023/02/02 20:14] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:14] | ------------------------------------------------------------
[2023/02/02 20:14] |   TRAIN(108)     0:01:40     0:01:15     0:00:25      0.0388
[2023/02/02 20:14] | ------------------------------------------------------------
[2023/02/02 20:14] | ****************************************************************************************************
[2023/02/02 20:15] | TRAIN(e109|iter10150): [13/93] Batch: 1.2044 (1.1404) Data: 0.5115 (0.8448) Loss: 0.0846 (0.0382)
[2023/02/02 20:16] | TRAIN(e109|iter10200): [63/93] Batch: 1.1862 (1.0906) Data: 0.8498 (0.8203) Loss: 0.0281 (0.0353)
[2023/02/02 20:16] | ------------------------------------------------------------
[2023/02/02 20:16] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:16] | ------------------------------------------------------------
[2023/02/02 20:16] |   TRAIN(109)     0:01:42     0:01:17     0:00:25      0.0364
[2023/02/02 20:16] | ------------------------------------------------------------
[2023/02/02 20:16] | ====================================================================================================
[2023/02/02 20:18] | idx 0 case case0008 mean_dice 0.612860 mean_hd95 20.890931
[2023/02/02 20:19] | idx 1 case case0022 mean_dice 0.900326 mean_hd95 2.396044
[2023/02/02 20:21] | idx 2 case case0038 mean_dice 0.786152 mean_hd95 60.201622
[2023/02/02 20:23] | idx 3 case case0036 mean_dice 0.801626 mean_hd95 12.733611
[2023/02/02 20:25] | idx 4 case case0032 mean_dice 0.772509 mean_hd95 20.121913
[2023/02/02 20:27] | idx 5 case case0002 mean_dice 0.869131 mean_hd95 20.420955
[2023/02/02 20:29] | idx 6 case case0029 mean_dice 0.721115 mean_hd95 45.280773
[2023/02/02 20:32] | idx 7 case case0003 mean_dice 0.725213 mean_hd95 97.594306
[2023/02/02 20:34] | idx 8 case case0001 mean_dice 0.751834 mean_hd95 43.067814
[2023/02/02 20:36] | idx 9 case case0004 mean_dice 0.748558 mean_hd95 8.227430
[2023/02/02 20:37] | idx 10 case case0025 mean_dice 0.852689 mean_hd95 36.853142
[2023/02/02 20:38] | idx 11 case case0035 mean_dice 0.854374 mean_hd95 19.449536
[2023/02/02 20:38] | Mean class 1 mean_dice 0.873283 mean_hd95 13.005858
[2023/02/02 20:38] | Mean class 2 mean_dice 0.615958 mean_hd95 35.570793
[2023/02/02 20:38] | Mean class 3 mean_dice 0.818099 mean_hd95 52.299334
[2023/02/02 20:38] | Mean class 4 mean_dice 0.794430 mean_hd95 64.867903
[2023/02/02 20:38] | Mean class 5 mean_dice 0.942681 mean_hd95 24.042609
[2023/02/02 20:38] | Mean class 6 mean_dice 0.609474 mean_hd95 12.446830
[2023/02/02 20:38] | Mean class 7 mean_dice 0.857153 mean_hd95 34.053892
[2023/02/02 20:38] | Mean class 8 mean_dice 0.753179 mean_hd95 21.871499
[2023/02/02 20:38] | Testing performance>>  mean_dice : 0.783032  mean_hd95 : 32.269840
[2023/02/02 20:38] | ====================================================================================================
[2023/02/02 20:38] | ****************************************************************************************************
[2023/02/02 20:38] | TRAIN(e110|iter10250): [20/93] Batch: 1.1949 (1.1823) Data: 0.7132 (0.9026) Loss: 0.0339 (0.0350)
[2023/02/02 20:39] | TRAIN(e110|iter10300): [70/93] Batch: 1.3123 (1.1335) Data: 0.7256 (0.8613) Loss: 0.0312 (0.0367)
[2023/02/02 20:40] | ------------------------------------------------------------
[2023/02/02 20:40] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:40] | ------------------------------------------------------------
[2023/02/02 20:40] |   TRAIN(110)     0:01:44     0:01:19     0:00:25      0.0356
[2023/02/02 20:40] | ------------------------------------------------------------
[2023/02/02 20:40] | ****************************************************************************************************
[2023/02/02 20:40] | TRAIN(e111|iter10350): [27/93] Batch: 1.2122 (1.1376) Data: 0.9128 (0.8696) Loss: 0.0316 (0.0383)
[2023/02/02 20:41] | TRAIN(e111|iter10400): [77/93] Batch: 0.9821 (1.1223) Data: 0.9864 (0.8530) Loss: 0.0232 (0.0348)
[2023/02/02 20:41] | ------------------------------------------------------------
[2023/02/02 20:41] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:41] | ------------------------------------------------------------
[2023/02/02 20:41] |   TRAIN(111)     0:01:43     0:01:18     0:00:25      0.0346
[2023/02/02 20:41] | ------------------------------------------------------------
[2023/02/02 20:41] | ****************************************************************************************************
[2023/02/02 20:42] | TRAIN(e112|iter10450): [34/93] Batch: 1.2910 (1.2044) Data: 0.9147 (0.9278) Loss: 0.0266 (0.0349)
[2023/02/02 20:43] | TRAIN(e112|iter10500): [84/93] Batch: 1.1591 (1.1867) Data: 0.9958 (0.9121) Loss: 0.0292 (0.0345)
[2023/02/02 20:43] | ------------------------------------------------------------
[2023/02/02 20:43] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:43] | ------------------------------------------------------------
[2023/02/02 20:43] |   TRAIN(112)     0:01:48     0:01:23     0:00:25      0.0353
[2023/02/02 20:43] | ------------------------------------------------------------
[2023/02/02 20:43] | ****************************************************************************************************
[2023/02/02 20:44] | TRAIN(e113|iter10550): [41/93] Batch: 1.1540 (1.0748) Data: 0.5265 (0.7968) Loss: 0.0284 (0.0320)
[2023/02/02 20:45] | TRAIN(e113|iter10600): [91/93] Batch: 0.9134 (1.0774) Data: 0.7848 (0.8051) Loss: 0.0305 (0.0343)
[2023/02/02 20:45] | ------------------------------------------------------------
[2023/02/02 20:45] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:45] | ------------------------------------------------------------
[2023/02/02 20:45] |   TRAIN(113)     0:01:39     0:01:14     0:00:25      0.0344
[2023/02/02 20:45] | ------------------------------------------------------------
[2023/02/02 20:45] | ****************************************************************************************************
[2023/02/02 20:46] | TRAIN(e114|iter10650): [48/93] Batch: 1.0371 (1.0774) Data: 1.0076 (0.8097) Loss: 0.0315 (0.0348)
[2023/02/02 20:46] | ------------------------------------------------------------
[2023/02/02 20:46] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:46] | ------------------------------------------------------------
[2023/02/02 20:46] |   TRAIN(114)     0:01:39     0:01:14     0:00:25      0.0351
[2023/02/02 20:46] | ------------------------------------------------------------
[2023/02/02 20:46] | ****************************************************************************************************
[2023/02/02 20:47] | TRAIN(e115|iter10700): [ 5/93] Batch: 1.1745 (1.1986) Data: 0.9049 (0.9178) Loss: 0.0393 (0.0306)
[2023/02/02 20:47] | TRAIN(e115|iter10750): [55/93] Batch: 1.0417 (1.1212) Data: 0.6897 (0.8452) Loss: 0.0330 (0.0346)
[2023/02/02 20:48] | ------------------------------------------------------------
[2023/02/02 20:48] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:48] | ------------------------------------------------------------
[2023/02/02 20:48] |   TRAIN(115)     0:01:42     0:01:17     0:00:25      0.0344
[2023/02/02 20:48] | ------------------------------------------------------------
[2023/02/02 20:48] | ****************************************************************************************************
[2023/02/02 20:48] | TRAIN(e116|iter10800): [12/93] Batch: 1.0330 (1.1662) Data: 0.8508 (0.8895) Loss: 0.0260 (0.0385)
[2023/02/02 20:49] | TRAIN(e116|iter10850): [62/93] Batch: 1.2003 (1.2183) Data: 0.8212 (0.9420) Loss: 0.0303 (0.0326)
[2023/02/02 20:50] | ------------------------------------------------------------
[2023/02/02 20:50] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:50] | ------------------------------------------------------------
[2023/02/02 20:50] |   TRAIN(116)     0:01:52     0:01:27     0:00:25      0.0329
[2023/02/02 20:50] | ------------------------------------------------------------
[2023/02/02 20:50] | ****************************************************************************************************
[2023/02/02 20:50] | TRAIN(e117|iter10900): [19/93] Batch: 1.3643 (1.1848) Data: 0.9432 (0.9136) Loss: 0.0275 (0.0338)
[2023/02/02 20:51] | TRAIN(e117|iter10950): [69/93] Batch: 0.8650 (1.1574) Data: 1.2470 (0.8898) Loss: 0.0288 (0.0362)
[2023/02/02 20:52] | ------------------------------------------------------------
[2023/02/02 20:52] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:52] | ------------------------------------------------------------
[2023/02/02 20:52] |   TRAIN(117)     0:01:47     0:01:22     0:00:25      0.0369
[2023/02/02 20:52] | ------------------------------------------------------------
[2023/02/02 20:52] | ****************************************************************************************************
[2023/02/02 20:52] | TRAIN(e118|iter11000): [26/93] Batch: 1.1084 (1.1397) Data: 1.1712 (0.8788) Loss: 0.0304 (0.0428)
[2023/02/02 20:53] | TRAIN(e118|iter11050): [76/93] Batch: 0.7873 (1.1327) Data: 1.1293 (0.8641) Loss: 0.0342 (0.0362)
[2023/02/02 20:54] | ------------------------------------------------------------
[2023/02/02 20:54] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:54] | ------------------------------------------------------------
[2023/02/02 20:54] |   TRAIN(118)     0:01:45     0:01:19     0:00:25      0.0361
[2023/02/02 20:54] | ------------------------------------------------------------
[2023/02/02 20:54] | ****************************************************************************************************
[2023/02/02 20:54] | TRAIN(e119|iter11100): [33/93] Batch: 1.1362 (1.1280) Data: 1.0503 (0.8617) Loss: 0.0263 (0.0379)
[2023/02/02 20:55] | TRAIN(e119|iter11150): [83/93] Batch: 0.9954 (1.1202) Data: 1.1256 (0.8511) Loss: 0.0297 (0.0345)
[2023/02/02 20:55] | ------------------------------------------------------------
[2023/02/02 20:55] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 20:55] | ------------------------------------------------------------
[2023/02/02 20:55] |   TRAIN(119)     0:01:43     0:01:18     0:00:25      0.0348
[2023/02/02 20:55] | ------------------------------------------------------------
[2023/02/02 20:55] | ====================================================================================================
[2023/02/02 20:57] | idx 0 case case0008 mean_dice 0.619029 mean_hd95 22.320355
[2023/02/02 20:59] | idx 1 case case0022 mean_dice 0.897245 mean_hd95 3.301777
[2023/02/02 21:00] | idx 2 case case0038 mean_dice 0.795847 mean_hd95 30.767986
[2023/02/02 21:03] | idx 3 case case0036 mean_dice 0.807130 mean_hd95 23.422864
[2023/02/02 21:05] | idx 4 case case0032 mean_dice 0.778464 mean_hd95 19.702010
[2023/02/02 21:07] | idx 5 case case0002 mean_dice 0.872240 mean_hd95 12.380676
[2023/02/02 21:08] | idx 6 case case0029 mean_dice 0.721983 mean_hd95 45.728002
[2023/02/02 21:11] | idx 7 case case0003 mean_dice 0.726996 mean_hd95 98.020916
[2023/02/02 21:13] | idx 8 case case0001 mean_dice 0.747385 mean_hd95 41.735110
[2023/02/02 21:15] | idx 9 case case0004 mean_dice 0.780955 mean_hd95 11.926767
[2023/02/02 21:16] | idx 10 case case0025 mean_dice 0.840168 mean_hd95 37.468782
[2023/02/02 21:17] | idx 11 case case0035 mean_dice 0.861512 mean_hd95 8.247959
[2023/02/02 21:17] | Mean class 1 mean_dice 0.877196 mean_hd95 15.946662
[2023/02/02 21:17] | Mean class 2 mean_dice 0.633222 mean_hd95 36.649636
[2023/02/02 21:17] | Mean class 3 mean_dice 0.824919 mean_hd95 52.543643
[2023/02/02 21:17] | Mean class 4 mean_dice 0.805707 mean_hd95 39.222940
[2023/02/02 21:17] | Mean class 5 mean_dice 0.942633 mean_hd95 26.527197
[2023/02/02 21:17] | Mean class 6 mean_dice 0.594480 mean_hd95 12.040848
[2023/02/02 21:17] | Mean class 7 mean_dice 0.854160 mean_hd95 33.314160
[2023/02/02 21:17] | Mean class 8 mean_dice 0.766985 mean_hd95 20.437049
[2023/02/02 21:17] | Testing performance>>  mean_dice : 0.787413  mean_hd95 : 29.585267
[2023/02/02 21:17] | ====================================================================================================
[2023/02/02 21:17] | >>>>> best model is changed <<<<<
[2023/02/02 21:17] | ****************************************************************************************************
[2023/02/02 21:18] | TRAIN(e120|iter11200): [40/93] Batch: 0.9661 (1.1289) Data: 0.9474 (0.8605) Loss: 0.0280 (0.0305)
[2023/02/02 21:19] | TRAIN(e120|iter11250): [90/93] Batch: 1.0500 (1.1352) Data: 0.5455 (0.8611) Loss: 0.0830 (0.0321)
[2023/02/02 21:19] | ------------------------------------------------------------
[2023/02/02 21:19] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 21:19] | ------------------------------------------------------------
[2023/02/02 21:19] |   TRAIN(120)     0:01:44     0:01:19     0:00:25      0.0326
[2023/02/02 21:19] | ------------------------------------------------------------
[2023/02/02 21:19] | ****************************************************************************************************
[2023/02/02 21:20] | TRAIN(e121|iter11300): [47/93] Batch: 1.3441 (1.1143) Data: 0.9050 (0.8435) Loss: 0.0356 (0.0349)
[2023/02/02 21:20] | ------------------------------------------------------------
[2023/02/02 21:20] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 21:20] | ------------------------------------------------------------
[2023/02/02 21:20] |   TRAIN(121)     0:01:43     0:01:18     0:00:25      0.0335
[2023/02/02 21:20] | ------------------------------------------------------------
[2023/02/02 21:20] | ****************************************************************************************************
[2023/02/02 21:21] | TRAIN(e122|iter11350): [ 4/93] Batch: 1.2746 (1.0749) Data: 1.0015 (0.8433) Loss: 0.0282 (0.0380)
[2023/02/02 21:21] | TRAIN(e122|iter11400): [54/93] Batch: 1.1599 (1.1208) Data: 1.1378 (0.8503) Loss: 0.0276 (0.0335)
[2023/02/02 21:22] | ------------------------------------------------------------
[2023/02/02 21:22] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 21:22] | ------------------------------------------------------------
[2023/02/02 21:22] |   TRAIN(122)     0:01:46     0:01:21     0:00:25      0.0338
[2023/02/02 21:22] | ------------------------------------------------------------
[2023/02/02 21:22] | ****************************************************************************************************
[2023/02/02 21:22] | TRAIN(e123|iter11450): [11/93] Batch: 1.1500 (1.2178) Data: 0.9801 (0.9479) Loss: 0.0284 (0.0329)
[2023/02/02 21:23] | TRAIN(e123|iter11500): [61/93] Batch: 1.2563 (1.2038) Data: 0.8333 (0.9282) Loss: 0.0279 (0.0344)
[2023/02/02 21:24] | ------------------------------------------------------------
[2023/02/02 21:24] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 21:24] | ------------------------------------------------------------
[2023/02/02 21:24] |   TRAIN(123)     0:01:48     0:01:23     0:00:25      0.0352
[2023/02/02 21:24] | ------------------------------------------------------------
[2023/02/02 21:24] | ****************************************************************************************************
[2023/02/02 21:24] | TRAIN(e124|iter11550): [18/93] Batch: 0.9754 (1.1363) Data: 0.9534 (0.8674) Loss: 0.0266 (0.0346)
[2023/02/02 21:25] | TRAIN(e124|iter11600): [68/93] Batch: 0.8412 (1.1226) Data: 0.7058 (0.8479) Loss: 0.0299 (0.0330)
[2023/02/02 21:26] | ------------------------------------------------------------
[2023/02/02 21:26] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 21:26] | ------------------------------------------------------------
[2023/02/02 21:26] |   TRAIN(124)     0:01:44     0:01:18     0:00:25      0.0340
[2023/02/02 21:26] | ------------------------------------------------------------
[2023/02/02 21:26] | ****************************************************************************************************
[2023/02/02 21:26] | TRAIN(e125|iter11650): [25/93] Batch: 1.0985 (1.1959) Data: 0.8529 (0.9181) Loss: 0.0279 (0.0340)
[2023/02/02 21:27] | TRAIN(e125|iter11700): [75/93] Batch: 1.0979 (1.1262) Data: 0.9816 (0.8546) Loss: 0.0237 (0.0359)
[2023/02/02 21:27] | ------------------------------------------------------------
[2023/02/02 21:27] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 21:27] | ------------------------------------------------------------
[2023/02/02 21:27] |   TRAIN(125)     0:01:43     0:01:17     0:00:25      0.0348
[2023/02/02 21:27] | ------------------------------------------------------------
[2023/02/02 21:27] | ****************************************************************************************************
[2023/02/02 21:28] | TRAIN(e126|iter11750): [32/93] Batch: 1.0914 (1.1043) Data: 0.8165 (0.8317) Loss: 0.0296 (0.0325)
[2023/02/02 21:29] | TRAIN(e126|iter11800): [82/93] Batch: 1.2723 (1.1070) Data: 1.0843 (0.8373) Loss: 0.0231 (0.0350)
[2023/02/02 21:29] | ------------------------------------------------------------
[2023/02/02 21:29] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 21:29] | ------------------------------------------------------------
[2023/02/02 21:29] |   TRAIN(126)     0:01:42     0:01:17     0:00:25      0.0352
[2023/02/02 21:29] | ------------------------------------------------------------
[2023/02/02 21:29] | ****************************************************************************************************
[2023/02/02 21:30] | TRAIN(e127|iter11850): [39/93] Batch: 1.1813 (1.1756) Data: 0.8158 (0.8976) Loss: 0.0279 (0.0375)
[2023/02/02 21:31] | TRAIN(e127|iter11900): [89/93] Batch: 0.8075 (1.1492) Data: 0.6939 (0.8738) Loss: 0.0272 (0.0350)
[2023/02/02 21:31] | ------------------------------------------------------------
[2023/02/02 21:31] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 21:31] | ------------------------------------------------------------
[2023/02/02 21:31] |   TRAIN(127)     0:01:45     0:01:20     0:00:25      0.0354
[2023/02/02 21:31] | ------------------------------------------------------------
[2023/02/02 21:31] | ****************************************************************************************************
[2023/02/02 21:32] | TRAIN(e128|iter11950): [46/93] Batch: 1.0885 (1.1377) Data: 0.9104 (0.8665) Loss: 0.0274 (0.0346)
[2023/02/02 21:33] | ------------------------------------------------------------
[2023/02/02 21:33] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 21:33] | ------------------------------------------------------------
[2023/02/02 21:33] |   TRAIN(128)     0:01:45     0:01:19     0:00:25      0.0348
[2023/02/02 21:33] | ------------------------------------------------------------
[2023/02/02 21:33] | ****************************************************************************************************
[2023/02/02 21:33] | TRAIN(e129|iter12000): [ 3/93] Batch: 1.3480 (1.0061) Data: 0.7426 (0.7367) Loss: 0.0240 (0.0398)
[2023/02/02 21:34] | TRAIN(e129|iter12050): [53/93] Batch: 1.1152 (1.1197) Data: 1.0589 (0.8514) Loss: 0.0359 (0.0317)
[2023/02/02 21:34] | ------------------------------------------------------------
[2023/02/02 21:34] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 21:34] | ------------------------------------------------------------
[2023/02/02 21:34] |   TRAIN(129)     0:01:44     0:01:19     0:00:25      0.0319
[2023/02/02 21:34] | ------------------------------------------------------------
[2023/02/02 21:34] | ====================================================================================================
[2023/02/02 21:36] | idx 0 case case0008 mean_dice 0.630526 mean_hd95 31.995316
[2023/02/02 21:38] | idx 1 case case0022 mean_dice 0.891025 mean_hd95 6.373201
[2023/02/02 21:39] | idx 2 case case0038 mean_dice 0.792344 mean_hd95 40.522177
[2023/02/02 21:42] | idx 3 case case0036 mean_dice 0.810967 mean_hd95 23.418161
[2023/02/02 21:44] | idx 4 case case0032 mean_dice 0.779667 mean_hd95 20.595981
[2023/02/02 21:46] | idx 5 case case0002 mean_dice 0.877622 mean_hd95 11.598436
[2023/02/02 21:47] | idx 6 case case0029 mean_dice 0.734374 mean_hd95 30.115074
[2023/02/02 21:50] | idx 7 case case0003 mean_dice 0.727011 mean_hd95 86.190974
[2023/02/02 21:52] | idx 8 case case0001 mean_dice 0.750112 mean_hd95 41.816948
[2023/02/02 21:54] | idx 9 case case0004 mean_dice 0.780038 mean_hd95 7.763926
[2023/02/02 21:55] | idx 10 case case0025 mean_dice 0.826688 mean_hd95 38.314144
[2023/02/02 21:56] | idx 11 case case0035 mean_dice 0.859521 mean_hd95 16.668029
[2023/02/02 21:56] | Mean class 1 mean_dice 0.878472 mean_hd95 13.076987
[2023/02/02 21:56] | Mean class 2 mean_dice 0.641071 mean_hd95 38.408208
[2023/02/02 21:56] | Mean class 3 mean_dice 0.837164 mean_hd95 68.066279
[2023/02/02 21:56] | Mean class 4 mean_dice 0.800698 mean_hd95 21.719801
[2023/02/02 21:56] | Mean class 5 mean_dice 0.945477 mean_hd95 21.269118
[2023/02/02 21:56] | Mean class 6 mean_dice 0.592478 mean_hd95 12.838162
[2023/02/02 21:56] | Mean class 7 mean_dice 0.848981 mean_hd95 41.336375
[2023/02/02 21:56] | Mean class 8 mean_dice 0.762258 mean_hd95 20.199980
[2023/02/02 21:56] | Testing performance>>  mean_dice : 0.788325  mean_hd95 : 29.614364
[2023/02/02 21:56] | ====================================================================================================
[2023/02/02 21:56] | >>>>> best model is changed <<<<<
[2023/02/02 21:56] | ****************************************************************************************************
[2023/02/02 21:56] | TRAIN(e130|iter12100): [10/93] Batch: 1.2011 (1.1809) Data: 1.0105 (0.9214) Loss: 0.0350 (0.0299)
[2023/02/02 21:57] | TRAIN(e130|iter12150): [60/93] Batch: 1.1150 (1.1733) Data: 1.0198 (0.9050) Loss: 0.0255 (0.0307)
[2023/02/02 21:58] | ------------------------------------------------------------
[2023/02/02 21:58] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 21:58] | ------------------------------------------------------------
[2023/02/02 21:58] |   TRAIN(130)     0:01:45     0:01:20     0:00:25      0.0324
[2023/02/02 21:58] | ------------------------------------------------------------
[2023/02/02 21:58] | ****************************************************************************************************
[2023/02/02 21:58] | TRAIN(e131|iter12200): [17/93] Batch: 1.2478 (1.1226) Data: 1.0406 (0.8623) Loss: 0.0294 (0.0350)
[2023/02/02 21:59] | TRAIN(e131|iter12250): [67/93] Batch: 1.2151 (1.0812) Data: 0.7327 (0.8095) Loss: 0.0250 (0.0351)
[2023/02/02 22:00] | ------------------------------------------------------------
[2023/02/02 22:00] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:00] | ------------------------------------------------------------
[2023/02/02 22:00] |   TRAIN(131)     0:01:38     0:01:13     0:00:25      0.0344
[2023/02/02 22:00] | ------------------------------------------------------------
[2023/02/02 22:00] | ****************************************************************************************************
[2023/02/02 22:00] | TRAIN(e132|iter12300): [24/93] Batch: 1.2495 (1.1072) Data: 1.0069 (0.8426) Loss: 0.0322 (0.0363)
[2023/02/02 22:01] | TRAIN(e132|iter12350): [74/93] Batch: 1.1281 (1.1158) Data: 0.8055 (0.8435) Loss: 0.0301 (0.0339)
[2023/02/02 22:01] | ------------------------------------------------------------
[2023/02/02 22:01] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:01] | ------------------------------------------------------------
[2023/02/02 22:01] |   TRAIN(132)     0:01:42     0:01:17     0:00:25      0.0332
[2023/02/02 22:01] | ------------------------------------------------------------
[2023/02/02 22:01] | ****************************************************************************************************
[2023/02/02 22:02] | TRAIN(e133|iter12400): [31/93] Batch: 1.1463 (1.0894) Data: 0.7415 (0.8148) Loss: 0.0251 (0.0347)
[2023/02/02 22:03] | TRAIN(e133|iter12450): [81/93] Batch: 1.1223 (1.0983) Data: 0.9570 (0.8275) Loss: 0.0292 (0.0328)
[2023/02/02 22:03] | ------------------------------------------------------------
[2023/02/02 22:03] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:03] | ------------------------------------------------------------
[2023/02/02 22:03] |   TRAIN(133)     0:01:42     0:01:16     0:00:25      0.0328
[2023/02/02 22:03] | ------------------------------------------------------------
[2023/02/02 22:03] | ****************************************************************************************************
[2023/02/02 22:04] | TRAIN(e134|iter12500): [38/93] Batch: 1.2327 (1.2276) Data: 1.0138 (0.9557) Loss: 0.0266 (0.0346)
[2023/02/02 22:05] | TRAIN(e134|iter12550): [88/93] Batch: 1.1396 (1.1997) Data: 0.8365 (0.9242) Loss: 0.0249 (0.0332)
[2023/02/02 22:05] | ------------------------------------------------------------
[2023/02/02 22:05] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:05] | ------------------------------------------------------------
[2023/02/02 22:05] |   TRAIN(134)     0:01:50     0:01:24     0:00:25      0.0340
[2023/02/02 22:05] | ------------------------------------------------------------
[2023/02/02 22:05] | ****************************************************************************************************
[2023/02/02 22:06] | TRAIN(e135|iter12600): [45/93] Batch: 1.0175 (1.1044) Data: 0.7598 (0.8322) Loss: 0.0308 (0.0419)
[2023/02/02 22:07] | ------------------------------------------------------------
[2023/02/02 22:07] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:07] | ------------------------------------------------------------
[2023/02/02 22:07] |   TRAIN(135)     0:01:43     0:01:18     0:00:25      0.0370
[2023/02/02 22:07] | ------------------------------------------------------------
[2023/02/02 22:07] | ****************************************************************************************************
[2023/02/02 22:07] | TRAIN(e136|iter12650): [ 2/93] Batch: 0.9370 (1.1637) Data: 0.6917 (0.8280) Loss: 0.0255 (0.0264)
[2023/02/02 22:08] | TRAIN(e136|iter12700): [52/93] Batch: 1.2314 (1.1286) Data: 0.7469 (0.8535) Loss: 0.0228 (0.0331)
[2023/02/02 22:08] | ------------------------------------------------------------
[2023/02/02 22:08] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:08] | ------------------------------------------------------------
[2023/02/02 22:08] |   TRAIN(136)     0:01:44     0:01:19     0:00:25      0.0317
[2023/02/02 22:08] | ------------------------------------------------------------
[2023/02/02 22:08] | ****************************************************************************************************
[2023/02/02 22:08] | TRAIN(e137|iter12750): [ 9/93] Batch: 1.2632 (1.1633) Data: 0.6475 (0.8675) Loss: 0.0384 (0.0399)
[2023/02/02 22:09] | TRAIN(e137|iter12800): [59/93] Batch: 1.3990 (1.1207) Data: 0.8277 (0.8489) Loss: 0.0790 (0.0333)
[2023/02/02 22:10] | ------------------------------------------------------------
[2023/02/02 22:10] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:10] | ------------------------------------------------------------
[2023/02/02 22:10] |   TRAIN(137)     0:01:42     0:01:16     0:00:25      0.0333
[2023/02/02 22:10] | ------------------------------------------------------------
[2023/02/02 22:10] | ****************************************************************************************************
[2023/02/02 22:10] | TRAIN(e138|iter12850): [16/93] Batch: 1.0209 (1.1975) Data: 0.9121 (0.9222) Loss: 0.0292 (0.0314)
[2023/02/02 22:11] | TRAIN(e138|iter12900): [66/93] Batch: 1.1214 (1.2159) Data: 0.9059 (0.9404) Loss: 0.0242 (0.0327)
[2023/02/02 22:12] | ------------------------------------------------------------
[2023/02/02 22:12] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:12] | ------------------------------------------------------------
[2023/02/02 22:12] |   TRAIN(138)     0:01:49     0:01:24     0:00:25      0.0321
[2023/02/02 22:12] | ------------------------------------------------------------
[2023/02/02 22:12] | ****************************************************************************************************
[2023/02/02 22:12] | TRAIN(e139|iter12950): [23/93] Batch: 1.2105 (1.1125) Data: 0.9995 (0.8470) Loss: 0.0258 (0.0348)
[2023/02/02 22:13] | TRAIN(e139|iter13000): [73/93] Batch: 1.2803 (1.0863) Data: 0.7145 (0.8133) Loss: 0.0279 (0.0343)
[2023/02/02 22:13] | ------------------------------------------------------------
[2023/02/02 22:13] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:13] | ------------------------------------------------------------
[2023/02/02 22:13] |   TRAIN(139)     0:01:39     0:01:14     0:00:25      0.0334
[2023/02/02 22:13] | ------------------------------------------------------------
[2023/02/02 22:13] | ====================================================================================================
[2023/02/02 22:15] | idx 0 case case0008 mean_dice 0.637771 mean_hd95 22.239829
[2023/02/02 22:17] | idx 1 case case0022 mean_dice 0.887707 mean_hd95 6.849737
[2023/02/02 22:18] | idx 2 case case0038 mean_dice 0.788709 mean_hd95 25.776302
[2023/02/02 22:21] | idx 3 case case0036 mean_dice 0.811647 mean_hd95 23.488579
[2023/02/02 22:23] | idx 4 case case0032 mean_dice 0.772129 mean_hd95 20.990159
[2023/02/02 22:25] | idx 5 case case0002 mean_dice 0.876730 mean_hd95 11.487843
[2023/02/02 22:26] | idx 6 case case0029 mean_dice 0.721185 mean_hd95 44.649648
[2023/02/02 22:29] | idx 7 case case0003 mean_dice 0.727979 mean_hd95 90.006376
[2023/02/02 22:31] | idx 8 case case0001 mean_dice 0.742796 mean_hd95 41.596440
[2023/02/02 22:33] | idx 9 case case0004 mean_dice 0.772105 mean_hd95 8.179728
[2023/02/02 22:34] | idx 10 case case0025 mean_dice 0.824433 mean_hd95 38.646798
[2023/02/02 22:35] | idx 11 case case0035 mean_dice 0.856339 mean_hd95 20.621326
[2023/02/02 22:35] | Mean class 1 mean_dice 0.876438 mean_hd95 13.221060
[2023/02/02 22:35] | Mean class 2 mean_dice 0.633544 mean_hd95 36.343250
[2023/02/02 22:35] | Mean class 3 mean_dice 0.839529 mean_hd95 53.195072
[2023/02/02 22:35] | Mean class 4 mean_dice 0.802535 mean_hd95 46.325252
[2023/02/02 22:35] | Mean class 5 mean_dice 0.946294 mean_hd95 19.240096
[2023/02/02 22:35] | Mean class 6 mean_dice 0.572342 mean_hd95 12.502952
[2023/02/02 22:35] | Mean class 7 mean_dice 0.848163 mean_hd95 35.430580
[2023/02/02 22:35] | Mean class 8 mean_dice 0.760842 mean_hd95 20.096914
[2023/02/02 22:35] | Testing performance>>  mean_dice : 0.784961  mean_hd95 : 29.544397
[2023/02/02 22:35] | ====================================================================================================
[2023/02/02 22:35] | ****************************************************************************************************
[2023/02/02 22:36] | TRAIN(e140|iter13050): [30/93] Batch: 1.3035 (1.1292) Data: 0.7846 (0.8565) Loss: 0.0316 (0.0296)
[2023/02/02 22:37] | TRAIN(e140|iter13100): [80/93] Batch: 1.1441 (1.1454) Data: 0.9293 (0.8750) Loss: 0.0840 (0.0326)
[2023/02/02 22:37] | ------------------------------------------------------------
[2023/02/02 22:37] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:37] | ------------------------------------------------------------
[2023/02/02 22:37] |   TRAIN(140)     0:01:46     0:01:21     0:00:25      0.0349
[2023/02/02 22:37] | ------------------------------------------------------------
[2023/02/02 22:37] | ****************************************************************************************************
[2023/02/02 22:38] | TRAIN(e141|iter13150): [37/93] Batch: 1.1075 (1.2113) Data: 0.8241 (0.9354) Loss: 0.0327 (0.0316)
[2023/02/02 22:39] | TRAIN(e141|iter13200): [87/93] Batch: 1.2438 (1.1528) Data: 0.5279 (0.8775) Loss: 0.0279 (0.0307)
[2023/02/02 22:39] | ------------------------------------------------------------
[2023/02/02 22:39] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:39] | ------------------------------------------------------------
[2023/02/02 22:39] |   TRAIN(141)     0:01:45     0:01:20     0:00:25      0.0310
[2023/02/02 22:39] | ------------------------------------------------------------
[2023/02/02 22:39] | ****************************************************************************************************
[2023/02/02 22:39] | TRAIN(e142|iter13250): [44/93] Batch: 1.1900 (1.1085) Data: 0.8923 (0.8384) Loss: 0.0272 (0.0334)
[2023/02/02 22:40] | ------------------------------------------------------------
[2023/02/02 22:40] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:40] | ------------------------------------------------------------
[2023/02/02 22:40] |   TRAIN(142)     0:01:41     0:01:16     0:00:25      0.0328
[2023/02/02 22:40] | ------------------------------------------------------------
[2023/02/02 22:40] | ****************************************************************************************************
[2023/02/02 22:40] | TRAIN(e143|iter13300): [ 1/93] Batch: 1.0883 (1.0883) Data: 0.9469 (0.8856) Loss: 0.0281 (0.0280)
[2023/02/02 22:41] | TRAIN(e143|iter13350): [51/93] Batch: 1.1542 (1.0797) Data: 0.7831 (0.8070) Loss: 0.0258 (0.0321)
[2023/02/02 22:42] | ------------------------------------------------------------
[2023/02/02 22:42] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:42] | ------------------------------------------------------------
[2023/02/02 22:42] |   TRAIN(143)     0:01:38     0:01:13     0:00:25      0.0318
[2023/02/02 22:42] | ------------------------------------------------------------
[2023/02/02 22:42] | ****************************************************************************************************
[2023/02/02 22:42] | TRAIN(e144|iter13400): [ 8/93] Batch: 1.1032 (1.0700) Data: 0.4988 (0.7635) Loss: 0.0730 (0.0320)
[2023/02/02 22:43] | TRAIN(e144|iter13450): [58/93] Batch: 0.8114 (1.0455) Data: 0.7937 (0.7755) Loss: 0.0259 (0.0309)
[2023/02/02 22:44] | ------------------------------------------------------------
[2023/02/02 22:44] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:44] | ------------------------------------------------------------
[2023/02/02 22:44] |   TRAIN(144)     0:01:39     0:01:14     0:00:25      0.0308
[2023/02/02 22:44] | ------------------------------------------------------------
[2023/02/02 22:44] | ****************************************************************************************************
[2023/02/02 22:44] | TRAIN(e145|iter13500): [15/93] Batch: 1.1786 (1.1488) Data: 0.9077 (0.8769) Loss: 0.0221 (0.0270)
[2023/02/02 22:45] | TRAIN(e145|iter13550): [65/93] Batch: 1.1640 (1.1357) Data: 1.3050 (0.8686) Loss: 0.0232 (0.0319)
[2023/02/02 22:45] | ------------------------------------------------------------
[2023/02/02 22:45] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:45] | ------------------------------------------------------------
[2023/02/02 22:45] |   TRAIN(145)     0:01:43     0:01:18     0:00:25      0.0320
[2023/02/02 22:45] | ------------------------------------------------------------
[2023/02/02 22:45] | ****************************************************************************************************
[2023/02/02 22:46] | TRAIN(e146|iter13600): [22/93] Batch: 1.4863 (1.0763) Data: 0.9438 (0.8124) Loss: 0.0256 (0.0292)
[2023/02/02 22:47] | TRAIN(e146|iter13650): [72/93] Batch: 1.1343 (1.0839) Data: 0.9459 (0.8151) Loss: 0.0258 (0.0328)
[2023/02/02 22:47] | ------------------------------------------------------------
[2023/02/02 22:47] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:47] | ------------------------------------------------------------
[2023/02/02 22:47] |   TRAIN(146)     0:01:40     0:01:15     0:00:25      0.0329
[2023/02/02 22:47] | ------------------------------------------------------------
[2023/02/02 22:47] | ****************************************************************************************************
[2023/02/02 22:48] | TRAIN(e147|iter13700): [29/93] Batch: 0.8069 (1.0455) Data: 1.0165 (0.7830) Loss: 0.0763 (0.0347)
[2023/02/02 22:48] | TRAIN(e147|iter13750): [79/93] Batch: 0.8886 (1.0896) Data: 1.0260 (0.8207) Loss: 0.0325 (0.0338)
[2023/02/02 22:49] | ------------------------------------------------------------
[2023/02/02 22:49] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:49] | ------------------------------------------------------------
[2023/02/02 22:49] |   TRAIN(147)     0:01:39     0:01:14     0:00:25      0.0332
[2023/02/02 22:49] | ------------------------------------------------------------
[2023/02/02 22:49] | ****************************************************************************************************
[2023/02/02 22:49] | TRAIN(e148|iter13800): [36/93] Batch: 0.9237 (1.0958) Data: 0.6228 (0.8204) Loss: 0.0236 (0.0324)
[2023/02/02 22:50] | TRAIN(e148|iter13850): [86/93] Batch: 1.1283 (1.1077) Data: 1.1945 (0.8407) Loss: 0.0270 (0.0301)
[2023/02/02 22:50] | ------------------------------------------------------------
[2023/02/02 22:50] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:50] | ------------------------------------------------------------
[2023/02/02 22:50] |   TRAIN(148)     0:01:43     0:01:17     0:00:25      0.0298
[2023/02/02 22:50] | ------------------------------------------------------------
[2023/02/02 22:50] | ****************************************************************************************************
[2023/02/02 22:51] | TRAIN(e149|iter13900): [43/93] Batch: 1.0561 (1.2031) Data: 1.0320 (0.9299) Loss: 0.0451 (0.0311)
[2023/02/02 22:52] | ------------------------------------------------------------
[2023/02/02 22:52] |        Stage       Batch        Data       F+B+O        Loss
[2023/02/02 22:52] | ------------------------------------------------------------
[2023/02/02 22:52] |   TRAIN(149)     0:01:45     0:01:20     0:00:25      0.0299
[2023/02/02 22:52] | ------------------------------------------------------------
[2023/02/02 22:52] | ====================================================================================================
[2023/02/02 22:54] | idx 0 case case0008 mean_dice 0.631722 mean_hd95 32.386517
[2023/02/02 22:55] | idx 1 case case0022 mean_dice 0.893916 mean_hd95 6.414837
[2023/02/02 22:57] | idx 2 case case0038 mean_dice 0.786163 mean_hd95 27.221158
[2023/02/02 22:59] | idx 3 case case0036 mean_dice 0.805004 mean_hd95 25.584660
[2023/02/02 23:01] | idx 4 case case0032 mean_dice 0.773996 mean_hd95 21.039435
[2023/02/02 23:03] | idx 5 case case0002 mean_dice 0.874550 mean_hd95 21.510120
[2023/02/02 23:04] | idx 6 case case0029 mean_dice 0.742922 mean_hd95 43.941633
[2023/02/02 23:07] | idx 7 case case0003 mean_dice 0.731471 mean_hd95 93.267349
[2023/02/02 23:09] | idx 8 case case0001 mean_dice 0.747245 mean_hd95 43.103362
[2023/02/02 23:11] | idx 9 case case0004 mean_dice 0.778659 mean_hd95 7.752892
[2023/02/02 23:12] | idx 10 case case0025 mean_dice 0.839470 mean_hd95 38.216594
[2023/02/02 23:13] | idx 11 case case0035 mean_dice 0.857236 mean_hd95 17.034864
[2023/02/02 23:13] | Mean class 1 mean_dice 0.877729 mean_hd95 13.287149
[2023/02/02 23:13] | Mean class 2 mean_dice 0.636603 mean_hd95 37.932844
[2023/02/02 23:13] | Mean class 3 mean_dice 0.834728 mean_hd95 66.842750
[2023/02/02 23:13] | Mean class 4 mean_dice 0.801755 mean_hd95 36.977687
[2023/02/02 23:13] | Mean class 5 mean_dice 0.944915 mean_hd95 20.470476
[2023/02/02 23:13] | Mean class 6 mean_dice 0.602990 mean_hd95 13.601052
[2023/02/02 23:13] | Mean class 7 mean_dice 0.844720 mean_hd95 41.506688
[2023/02/02 23:13] | Mean class 8 mean_dice 0.764797 mean_hd95 21.030302
[2023/02/02 23:13] | Testing performance>>  mean_dice : 0.788530  mean_hd95 : 31.456118
[2023/02/02 23:13] | ====================================================================================================
[2023/02/02 23:13] | >>>>> best model is changed <<<<<
[2023/02/02 23:13] | ****************************************************************************************************

[2022/12/28 20:47] | Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet50_a1_0-14fe96d1.pth)
[2022/12/28 20:47] | ---------------------------------------------------------------------------------
[2022/12/28 20:47] |                                    INFORMATION
[2022/12/28 20:47] | ---------------------------------------------------------------------------------
[2022/12/28 20:47] | Project Name              | MECLA
[2022/12/28 20:47] | Project Administrator     | jaejung
[2022/12/28 20:47] | Experiment Name           | eyepacs_v1_resnet50_v1
[2022/12/28 20:47] | Experiment Start Time     | 2022-12-28 20:46:55
[2022/12/28 20:47] | Experiment Model Name     | resnet50
[2022/12/28 20:47] | Experiment Log Directory  | log/eyepacs_v1_resnet50_v1
[2022/12/28 20:47] | ---------------------------------------------------------------------------------
[2022/12/28 20:47] |                                 EXPERIMENT SETUP
[2022/12/28 20:47] | ---------------------------------------------------------------------------------
[2022/12/28 20:47] | train_size                | (224, 224)
[2022/12/28 20:47] | test_size                 | (224, 224)
[2022/12/28 20:47] | center_crop_ptr           | 0.875
[2022/12/28 20:47] | interpolation             | bicubic
[2022/12/28 20:47] | mean                      | (0.485, 0.456, 0.406)
[2022/12/28 20:47] | std                       | (0.229, 0.224, 0.225)
[2022/12/28 20:47] | hflip                     | 0.5
[2022/12/28 20:47] | auto_aug                  | False
[2022/12/28 20:47] | cutmix                    | None
[2022/12/28 20:47] | mixup                     | None
[2022/12/28 20:47] | remode                    | 0.2
[2022/12/28 20:47] | model_name                | resnet50
[2022/12/28 20:47] | lr                        | 0.001
[2022/12/28 20:47] | epoch                     | 2
[2022/12/28 20:47] | criterion                 | ce
[2022/12/28 20:47] | optimizer                 | adamw
[2022/12/28 20:47] | weight_decay              | 0.0001
[2022/12/28 20:47] | scheduler                 | cosine
[2022/12/28 20:47] | warmup_epoch              | 1
[2022/12/28 20:47] | batch_size                | 32
[2022/12/28 20:47] | ---------------------------------------------------------------------------------
[2022/12/28 20:47] |                                   DATA & MODEL
[2022/12/28 20:47] | ---------------------------------------------------------------------------------
[2022/12/28 20:47] | Model Parameters(M)       | 23518277
[2022/12/28 20:47] | Number of Train Examples  | 28100
[2022/12/28 20:47] | Number of Valid Examples  | 7026
[2022/12/28 20:47] | Number of Class           | 5
[2022/12/28 20:47] | Task                      | multiclass
[2022/12/28 20:47] | ---------------------------------------------------------------------------------
[2022/12/28 20:47] | TRAIN(000): [ 50/879] Batch: 0.0813 (0.1233) Data: 0.0094 (0.0505) Loss: 1.4262 (1.5736)
[2022/12/28 20:47] | TRAIN(000): [100/879] Batch: 0.0845 (0.1047) Data: 0.0104 (0.0314) Loss: 1.1496 (1.3798)
[2022/12/28 20:47] | TRAIN(000): [150/879] Batch: 0.0889 (0.0982) Data: 0.0119 (0.0249) Loss: 0.7980 (1.2068)
[2022/12/28 20:47] | TRAIN(000): [200/879] Batch: 0.0899 (0.0930) Data: 0.0102 (0.0212) Loss: 1.0807 (1.1311)
[2022/12/28 20:47] | TRAIN(000): [250/879] Batch: 0.0861 (0.0916) Data: 0.0095 (0.0193) Loss: 0.6836 (1.0717)
[2022/12/28 20:47] | TRAIN(000): [300/879] Batch: 0.0857 (0.0906) Data: 0.0104 (0.0180) Loss: 0.7923 (1.0361)
[2022/12/28 20:47] | TRAIN(000): [350/879] Batch: 0.0861 (0.0899) Data: 0.0122 (0.0171) Loss: 0.9936 (1.0081)
[2022/12/28 20:47] | TRAIN(000): [400/879] Batch: 0.0854 (0.0895) Data: 0.0115 (0.0165) Loss: 0.8142 (0.9833)
[2022/12/28 20:47] | TRAIN(000): [450/879] Batch: 0.0841 (0.0891) Data: 0.0112 (0.0159) Loss: 0.7125 (0.9653)
[2022/12/28 20:47] | TRAIN(000): [500/879] Batch: 0.0806 (0.0879) Data: 0.0083 (0.0153) Loss: 0.7153 (0.9481)
[2022/12/28 20:47] | TRAIN(000): [550/879] Batch: 0.0909 (0.0870) Data: 0.0103 (0.0148) Loss: 0.7950 (0.9348)
[2022/12/28 20:47] | TRAIN(000): [600/879] Batch: 0.0867 (0.0872) Data: 0.0116 (0.0146) Loss: 0.8606 (0.9212)
[2022/12/28 20:47] | TRAIN(000): [650/879] Batch: 0.0830 (0.0871) Data: 0.0094 (0.0147) Loss: 0.8019 (0.9114)
[2022/12/28 20:48] | TRAIN(000): [700/879] Batch: 0.3002 (0.0873) Data: 0.0083 (0.0149) Loss: 1.1595 (0.9015)
[2022/12/28 20:48] | TRAIN(000): [750/879] Batch: 0.0828 (0.0875) Data: 0.0103 (0.0153) Loss: 0.7432 (0.8947)
[2022/12/28 20:48] | TRAIN(000): [800/879] Batch: 0.0844 (0.0874) Data: 0.0106 (0.0150) Loss: 0.8191 (0.8878)
[2022/12/28 20:48] | TRAIN(000): [850/879] Batch: 0.0786 (0.0870) Data: 0.0089 (0.0148) Loss: 0.5511 (0.8810)
[2022/12/28 20:48] | ------------------------------------------------------------
[2022/12/28 20:48] |        Stage       Batch        Data       F+B+O        Loss
[2022/12/28 20:48] | ------------------------------------------------------------
[2022/12/28 20:48] |     TRAIN(0)     0:01:16     0:00:12     0:01:03      0.8766
[2022/12/28 20:48] | ------------------------------------------------------------
[2022/12/28 20:48] | VALID(000): [ 50/220] Batch: 0.0342 (0.0594) Data: 0.0104 (0.0443) Loss: 0.7758 (0.7364)
[2022/12/28 20:48] | VALID(000): [100/220] Batch: 0.0380 (0.0439) Data: 0.0106 (0.0283) Loss: 0.8832 (0.7454)
[2022/12/28 20:48] | VALID(000): [150/220] Batch: 0.0256 (0.0385) Data: 0.0129 (0.0228) Loss: 0.6496 (0.7370)
[2022/12/28 20:48] | VALID(000): [200/220] Batch: 0.0269 (0.0358) Data: 0.0104 (0.0200) Loss: 0.4276 (0.7392)
[2022/12/28 20:48] | ------------------------------------------------------------------------------------------------
[2022/12/28 20:48] |        Stage        Loss    accuracy       auroc    f1_score   precision      recall specificity
[2022/12/28 20:48] | ------------------------------------------------------------------------------------------------
[2022/12/28 20:48] |     VALID(0)      0.7402      0.7521      0.7794      0.7521      0.7521      0.7521      0.9380
[2022/12/28 20:48] | ------------------------------------------------------------------------------------------------
[2022/12/28 20:48] | ####################################################################################################
[2022/12/28 20:48] | TRAIN(001): [ 50/879] Batch: 0.0891 (0.1257) Data: 0.0131 (0.0501) Loss: 0.8323 (0.7754)
[2022/12/28 20:48] | TRAIN(001): [100/879] Batch: 0.0864 (0.1058) Data: 0.0108 (0.0310) Loss: 1.0817 (0.7775)
[2022/12/28 20:48] | TRAIN(001): [150/879] Batch: 0.0870 (0.0993) Data: 0.0121 (0.0246) Loss: 0.5917 (0.7651)
[2022/12/28 20:48] | TRAIN(001): [200/879] Batch: 0.0862 (0.0959) Data: 0.0114 (0.0214) Loss: 0.7761 (0.7567)
[2022/12/28 20:48] | TRAIN(001): [250/879] Batch: 0.0835 (0.0941) Data: 0.0113 (0.0195) Loss: 0.9384 (0.7501)
[2022/12/28 20:48] | TRAIN(001): [300/879] Batch: 0.0777 (0.0917) Data: 0.0104 (0.0180) Loss: 0.7391 (0.7461)
[2022/12/28 20:48] | TRAIN(001): [350/879] Batch: 0.0826 (0.0899) Data: 0.0087 (0.0168) Loss: 0.5560 (0.7430)
[2022/12/28 20:49] | TRAIN(001): [400/879] Batch: 0.0854 (0.0891) Data: 0.0112 (0.0161) Loss: 0.8192 (0.7441)
[2022/12/28 20:49] | TRAIN(001): [450/879] Batch: 0.0789 (0.0891) Data: 0.0089 (0.0156) Loss: 0.6069 (0.7405)
[2022/12/28 20:49] | TRAIN(001): [500/879] Batch: 0.0894 (0.0892) Data: 0.0132 (0.0152) Loss: 0.7048 (0.7353)
[2022/12/28 20:49] | TRAIN(001): [550/879] Batch: 0.0779 (0.0881) Data: 0.0084 (0.0147) Loss: 0.7669 (0.7325)
[2022/12/28 20:49] | TRAIN(001): [600/879] Batch: 0.0825 (0.0879) Data: 0.0099 (0.0145) Loss: 0.8050 (0.7316)
[2022/12/28 20:49] | TRAIN(001): [650/879] Batch: 0.0872 (0.0878) Data: 0.0108 (0.0143) Loss: 0.3543 (0.7257)
[2022/12/28 20:49] | TRAIN(001): [700/879] Batch: 0.0870 (0.0878) Data: 0.0125 (0.0141) Loss: 0.3498 (0.7222)
[2022/12/28 20:49] | TRAIN(001): [750/879] Batch: 0.0767 (0.0876) Data: 0.0101 (0.0139) Loss: 0.5592 (0.7185)
[2022/12/28 20:49] | TRAIN(001): [800/879] Batch: 0.0894 (0.0872) Data: 0.0114 (0.0137) Loss: 0.7062 (0.7166)
[2022/12/28 20:49] | TRAIN(001): [850/879] Batch: 0.0744 (0.0873) Data: 0.0088 (0.0136) Loss: 0.8158 (0.7155)
[2022/12/28 20:49] | ------------------------------------------------------------
[2022/12/28 20:49] |        Stage       Batch        Data       F+B+O        Loss
[2022/12/28 20:49] | ------------------------------------------------------------
[2022/12/28 20:49] |     TRAIN(1)     0:01:16     0:00:11     0:01:04      0.7149
[2022/12/28 20:49] | ------------------------------------------------------------
[2022/12/28 20:49] | VALID(001): [ 50/220] Batch: 0.0255 (0.0600) Data: 0.0119 (0.0428) Loss: 0.5405 (0.6105)
[2022/12/28 20:49] | VALID(001): [100/220] Batch: 0.0272 (0.0441) Data: 0.0126 (0.0275) Loss: 0.8000 (0.6279)
[2022/12/28 20:49] | VALID(001): [150/220] Batch: 0.0281 (0.0386) Data: 0.0113 (0.0222) Loss: 0.5852 (0.6216)
[2022/12/28 20:49] | VALID(001): [200/220] Batch: 0.0274 (0.0359) Data: 0.0112 (0.0195) Loss: 0.3125 (0.6234)
[2022/12/28 20:49] | ------------------------------------------------------------------------------------------------
[2022/12/28 20:49] |        Stage        Loss    accuracy       auroc    f1_score   precision      recall specificity
[2022/12/28 20:49] | ------------------------------------------------------------------------------------------------
[2022/12/28 20:49] |     VALID(1)      0.6213      0.7884      0.8410      0.7884      0.7884      0.7884      0.9471
[2022/12/28 20:49] | ------------------------------------------------------------------------------------------------
[2022/12/28 20:49] | ####################################################################################################
